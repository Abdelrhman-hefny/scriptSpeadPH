from ultralytics import YOLO
import os
import json
import cv2
import numpy as np
import re # ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ø¶Ø§ÙØ© Ø§Ø³ØªÙŠØ±Ø§Ø¯ re
from PIL import Image

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ MangaOCRØŒ ÙˆØ¥Ù„Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… EasyOCR
try:
    from manga_ocr import MangaOcr
    USE_MANGA_OCR = True
    print("âœ… Using MangaOCR for text validation (specialized for manga).")
except ImportError:
    import easyocr
    USE_MANGA_OCR = False
    print("âš ï¸ MangaOCR not found, falling back to EasyOCR. Install with: pip install manga-ocr")

# ==========================
# ğŸ”¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬
# ==========================
MODEL_FILENAME = "comic-speech-bubble-detector.pt"
model_path = os.path.join("C:/Users/abdoh/Downloads/testScript/model", MODEL_FILENAME)
cfg_path = r"C:\Users\abdoh\Downloads\testScript\config\temp-title.json"
with open(cfg_path, encoding="utf-8") as f:
    cfg = json.load(f)

# Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
folder = cfg["title"]
base = os.path.join(r"C:\Users\abdoh\Downloads", folder)

# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
image_folder = base
output_path = os.path.join(base, "cleaned", "all_bubbles.json")

print(image_folder)
print(output_path)

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©
CONFIDENCE_THRESHOLD = 0.05
IOU_THRESHOLD = 0.6
SLICE_OVERLAP = 300
SLICE_HEIGHT = 2500
MIN_BUBBLE_AREA = 2000
CONTAINMENT_THRESHOLD = 0.95
MIN_DIM_THRESHOLD = 100  # ØªØµÙÙŠØ© Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„ØªÙŠ Ø¹Ø±Ø¶Ù‡Ø§ Ø£Ùˆ Ø§Ø±ØªÙØ§Ø¹Ù‡Ø§ Ø£Ù‚Ù„ Ù…Ù† 100 Ø¨ÙƒØ³Ù„
# ØªÙ… ØªØ«Ø¨ÙŠØª YOLO_IMG_SIZE Ø¹Ù†Ø¯ 640 ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø°ÙŠ Ù‚Ø¯Ù…ØªÙ‡ Ù…Ø¤Ø®Ø±Ø§Ù‹
YOLO_IMG_SIZE = 640 

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
try:
    model = YOLO(model_path)
    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {MODEL_FILENAME}")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
    exit()

# ØªØ­Ù…ÙŠÙ„ OCR (Ù…Ø¹ Ø¯Ø¹Ù… Ù…Ù†ÙØµÙ„ Ù„Ù€ ja Ùˆ ko)
if USE_MANGA_OCR:
    try:
        ocr = MangaOcr()
        print("âœ… MangaOCR loaded successfully.")
    except Exception as e:
        print(f"âš ï¸ Failed to load MangaOCR: {e}. Falling back to EasyOCR.")
        USE_MANGA_OCR = False
        try:
            ocr_ja = easyocr.Reader(['en', 'ja'], gpu=True)
            ocr_ko = easyocr.Reader(['en', 'ko'], gpu=True)
            print("âœ… EasyOCR loaded (GPU) for English, Japanese, and Korean.")
        except Exception as e:
            ocr_ja = easyocr.Reader(['en', 'ja'], gpu=False)
            ocr_ko = easyocr.Reader(['en', 'ko'], gpu=False)
            print(f"âœ… EasyOCR loaded (CPU) for English, Japanese, and Korean: {e}")
else:
    try:
        ocr_ja = easyocr.Reader(['en', 'ja'], gpu=True)
        ocr_ko = easyocr.Reader(['en', 'ko'], gpu=True)
        print("âœ… EasyOCR loaded (GPU) for English, Japanese, and Korean.")
    except Exception as e:
        ocr_ja = easyocr.Reader(['en', 'ja'], gpu=False)
        ocr_ko = easyocr.Reader(['en', 'ko'], gpu=False)
        print(f"âœ… EasyOCR loaded (CPU) for English, Japanese, and Korean: {e}")

# ==========================
# ğŸ”¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
# ==========================
def preprocess_image(img):
    """ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ù„Ø²ÙŠØ§Ø¯Ø© ÙˆØ¶ÙˆØ­ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª."""
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)

    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# ğŸ”¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = max(0, h - slice_height)
            y_end = h
        slices.append((image[y_start:y_end, :].copy(), y_start))
        if y_end == h:
            break
        y_start += (slice_height - overlap)
    return slices

# ==========================
# ğŸ”¹ IOU Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø§Ø®Ù„
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = max(0, (x2 - x1)) * max(0, (y2 - y1))
    area2 = max(0, (X2 - X1)) * max(0, (Y2 - Y1))
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# ğŸ”¹ ÙØ­Øµ Ø§Ù„ØªØ¶Ù…ÙŠÙ† (Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©)
# ==========================
def is_contained(box_small, box_large):
    x1_s, y1_s, x2_s, y2_s = box_small
    x1_l, y1_l, x2_l, y2_l = box_large
    area_small = max(0, (x2_s - x1_s)) * max(0, (y2_s - y1_s))
    inter_x1 = max(x1_s, x1_l)
    inter_y1 = max(y1_s, y1_l)
    inter_x2 = min(x2_s, x2_l)
    inter_y2 = min(y2_s, y2_l)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    return inter_area / area_small >= CONTAINMENT_THRESHOLD if area_small > 0 else False

# ==========================
# ğŸ”¹ Ø¯Ù…Ø¬ ÙˆØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª (Ù…Ø¹ ØªÙØ¶ÙŠÙ„ Ø§Ù„Ø£ÙƒØ¨Ø±)
# ==========================
def merge_and_clean_boxes(boxes_raw, scores_raw, merge_iou_thresh=IOU_THRESHOLD):
    if not boxes_raw:
        return [], []
    boxes = np.array(boxes_raw, dtype=np.float32)
    scores = np.array(scores_raw, dtype=np.float32)
    areas = [(x2 - x1) * (y2 - y1) for x1, y1, x2, y2 in boxes]
    indices = np.argsort(-np.array(areas))  # Ø§Ù„ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø³Ø§Ø­Ø© (ØªÙ†Ø§Ø²Ù„ÙŠ)
    boxes = boxes[indices]
    scores = scores[indices]
    merged_boxes = []
    merged_scores = []
    processed = set()

    for i in range(len(boxes)):
        if i in processed:
            continue
        
        current_box = boxes[i]
        current_score = scores[i]
        
        # ğŸŒŸ Ù…Ù†Ø·Ù‚ ØªÙØ¶ÙŠÙ„ Ø§Ù„Ø£ÙƒØ¨Ø± ÙÙŠ Ø§Ù„Ø¯Ù…Ø¬
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙÙ‚Ø§Ø¹Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© (Ø§Ù„Ø£ÙƒØ¨Ø±) Ù…ØªØ¯Ø§Ø®Ù„Ø© Ù…Ø¹ ÙÙ‚Ø§Ø¹Ø§Øª Ø£ØµØºØ±ØŒ Ø³Ù†Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø£ÙƒØ¨Ø± ÙˆÙ†Ù‚ÙˆÙ… Ø¨Ø¯Ù…Ø¬ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§ØªÙ‡Ù…
        overlaps_indices = [i]
        for j in range(i + 1, len(boxes)):
            if j in processed:
                continue
            
            other_box = boxes[j]
            iou = box_iou(current_box, other_box)
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ¯Ø§Ø®Ù„ Ø¹Ø§Ù„ÙŠÙ‹Ø§ Ø£Ùˆ ÙƒØ§Ù†Øª Ø§Ù„ÙÙ‚Ø§Ø¹Ø© Ø§Ù„Ø£ØµØºØ± Ù…Ø­ØªÙˆØ§Ø© ÙÙŠ Ø§Ù„Ø£ÙƒØ¨Ø±
            if iou > merge_iou_thresh or is_contained(other_box, current_box):
                overlaps_indices.append(j)
        
        # Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…ØªØ¯Ø§Ø®Ù„Ø© Ù…Ø¹ Ø§Ù„Ø£ÙƒØ¨Ø± ÙÙŠ Ù…Ø±Ø¨Ø¹ ÙˆØ§Ø­Ø¯ (Ù‡Ùˆ Ø£Ø³Ù„ÙˆØ¨Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ ÙˆÙ‡Ùˆ Ø¬ÙŠØ¯)
        all_overlapping_boxes = boxes[overlaps_indices]
        x1_min = np.min(all_overlapping_boxes[:, 0])
        y1_min = np.min(all_overlapping_boxes[:, 1])
        x2_max = np.max(all_overlapping_boxes[:, 2])
        y2_max = np.max(all_overlapping_boxes[:, 3])
        w_box = x2_max - x1_min
        h_box = y2_max - y1_min
        
        if w_box >= MIN_DIM_THRESHOLD and h_box >= MIN_DIM_THRESHOLD and (w_box * h_box) >= MIN_BUBBLE_AREA:
            merged_boxes.append([x1_min, y1_min, x2_max, y2_max])
            merged_scores.append(np.max(scores[overlaps_indices])) # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø£Ø¹Ù„Ù‰ Ù†ØªÙŠØ¬Ø©
        
        # ØªØ­Ø¯ÙŠØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¯Ù…Ø¬Ù‡Ø§ ÙƒÙ…Ø¹Ø§Ù„Ø¬Ø©
        for idx in overlaps_indices:
            processed.add(idx)

    final_boxes = []
    final_scores = []
    suppressed = np.zeros(len(merged_boxes), dtype=bool)
    
    # Ù‡Ø°Ù‡ Ù…Ø±Ø­Ù„Ø© NMS Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ¯Ø§Ø®Ù„Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© (Ø£Ù‚Ù„ Ù…Ù† IOU_THRESHOLD)
    for i in range(len(merged_boxes)):
        if suppressed[i]:
            continue
        final_boxes.append(merged_boxes[i])
        final_scores.append(merged_scores[i])
        for j in range(i + 1, len(merged_boxes)):
            if suppressed[j]:
                continue
            # ÙŠØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ÙÙ‚Ø§Ø¹Ø© (j) Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªØ¯Ø§Ø®Ù„Ø© Ù…Ø¹ (i) Ø¨Ù…Ù‚Ø¯Ø§Ø± > 0.15 Ø£Ùˆ Ù…Ø­ØªÙˆØ§Ø© ÙÙŠÙ‡Ø§
            if box_iou(merged_boxes[i], merged_boxes[j]) > 0.15 or is_contained(merged_boxes[j], merged_boxes[i]):
                suppressed[j] = True
    
    return final_boxes, final_scores

# ==========================
# ğŸ”¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù†Øµ ÙÙ‚Ø·
# ==========================
def has_text(image, box, ocr_ja, ocr_ko):
    # ØªÙ… ØªØºÙŠÙŠØ± Ø§Ù„Ø¯Ø§Ù„Ø© Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ù†Øµ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠ Ø§Ù„Ø·ÙˆÙŠÙ„ØŒ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø°ÙŠ Ù‚Ø¯Ù…ØªÙ‡ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø·Ù„Ø¨
    x1, y1, x2, y2 = map(int, box)
    x1, y1 = max(0, x1-5), max(0, y1-5)
    x2, y2 = min(image.shape[1], x2+5), min(image.shape[0], y2+5)
    if x2 <= x1 or y2 <= y1:
        return False

    crop = image[y1:y2, x1:x2]
    if crop.size == 0:
        return False

    gray_crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    clahe_crop = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4,4))
    processed_crop = clahe_crop.apply(gray_crop)

    try:
        if USE_MANGA_OCR:
            pil_image = Image.fromarray(processed_crop)
            text = ocr(pil_image)
            return bool(text)  # Ø¥Ø±Ø¬Ø§Ø¹ True Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ Ø£ÙŠ Ù†Øµ
        else:
            # ÙØ­Øµ Ø¨Ù€ ocr_ja (en, ja)
            results = ocr_ja.readtext(processed_crop, detail=0)
            if results:  # Ø¥Ø±Ø¬Ø§Ø¹ True Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ Ø£ÙŠ Ù†Øµ
                return True
            # ÙØ­Øµ Ø¨Ù€ ocr_ko (en, ko)
            results = ocr_ko.readtext(processed_crop, detail=0)
            return bool(results)  # Ø¥Ø±Ø¬Ø§Ø¹ True Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ Ø£ÙŠ Ù†Øµ
    except Exception as e:
        # print(f"âš ï¸ OCR failed for box [{x1}, {y1}, {x2}, {y2}]: {e}") # Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
        return False

# ==========================
# ğŸ”¹ Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø­Ø³Ø§Ø¨ Ù…Ø±ÙƒØ² Ø§Ù„Ù…Ø±Ø¨Ø¹
# ==========================
def get_box_center(box):
    x1, y1, x2, y2 = box
    return (x1 + x2) / 2.0, (y1 + y2) / 2.0

# ==========================
# ğŸ”¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµÙˆØ±: {image_folder}")
    exit()

image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {img_path}")
        continue

    enhanced_img = preprocess_image(image)
    h, w, _ = image.shape
    all_boxes = []
    all_scores = []

    slices = slice_image(enhanced_img) if h > SLICE_HEIGHT else [(enhanced_img, 0)]
    for slice_img, offset_y in slices:
        results = model(slice_img, imgsz=YOLO_IMG_SIZE, conf=CONFIDENCE_THRESHOLD, iou=IOU_THRESHOLD, verbose=False)
        for r in results:
            if r.boxes:
                boxes = r.boxes.xyxy.cpu().numpy()
                scores = r.boxes.conf.cpu().numpy()
                for box, score in zip(boxes, scores):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    x1, y1, x2, y2 = box.tolist()
                    y1 += offset_y
                    y2 += offset_y
                    w_box = x2 - x1
                    h_box = y2 - y1
                    area = w_box * h_box
                    if area < MIN_BUBBLE_AREA or w_box < MIN_DIM_THRESHOLD or h_box < MIN_DIM_THRESHOLD:
                        continue
                    all_boxes.append([x1, y1, x2, y2])
                    all_scores.append(score)

    # ğŸŒŸ ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ù…Ù†Ø·Ù‚ ØªÙØ¶ÙŠÙ„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø© Ø§Ù„Ø£ÙƒØ¨Ø± Ø¯Ø§Ø®Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø©
    clean_boxes, clean_scores = merge_and_clean_boxes(all_boxes, all_scores, merge_iou_thresh=IOU_THRESHOLD)

    valid_bubbles_with_centers = []
    for box in clean_boxes:
        if USE_MANGA_OCR:
            if has_text(image, box, ocr, ocr):
                cx, cy = get_box_center(box)
                polygon = [[box[0], box[1]], [box[2], box[1]], [box[2], box[3]], [box[0], box[3]]]
                valid_bubbles_with_centers.append({'center_y': cy, 'center_x': cx, 'points': polygon})
        else:
            if has_text(image, box, ocr_ja, ocr_ko):
                cx, cy = get_box_center(box)
                polygon = [[box[0], box[1]], [box[2], box[1]], [box[2], box[3]], [box[0], box[3]]]
                valid_bubbles_with_centers.append({'center_y': cy, 'center_x': cx, 'points': polygon})

    # ØªØ±ØªÙŠØ¨ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø­Ø³Ø¨ center_y Ø«Ù… center_x
    valid_bubbles_with_centers.sort(key=lambda b: (b['center_y'], b['center_x']))

    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ JSON
    valid_bubbles = [{"id": i + 1, "points": [[int(round(x)), int(round(y))] for x, y in b['points']]}  
                     for i, b in enumerate(valid_bubbles_with_centers)]

    key = f"{idx:02d}_mask"
    all_bubbles[key] = valid_bubbles
    print(f"âœ… Processed {img_file}, found {len(valid_bubbles)} valid bubbles with text, sorted by position, no overlaps, min dim 100px.")

# ==========================
# ğŸ”¹ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2, ensure_ascii=False)

print(f"\nğŸ‰ All sorted, non-overlapping bubbles with text (min dim 100px) saved to:\n{output_path}")
from ultralytics import YOLO
import os
import json
import cv2
import numpy as np
import math

# ==========================
# 🔹 إعداد المسارات والنموذج
# ==========================
# 🚨 استخدم النموذج الأكثر دقة المُشار إليه في بيانات مشروعك
MODEL_FILENAME = "comic-speech-bubble-detector.pt" # أو "yolov8m.pt"
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

# إعدادات الحساسية
CONFIDENCE_THRESHOLD = 0.15  # تم خفضه لاكتشاف الفقاعات الملونة والغامقة
SLICE_OVERLAP = 300          # تداخل جيد للصور الطويلة
SLICE_HEIGHT = 2500

try:
    model = YOLO(model_path)
    print(f"✅ تم تحميل النموذج: {MODEL_FILENAME}")
except Exception as e:
    print(f"FATAL ERROR: Failed to load YOLO model from {model_path}. Error: {e}")
    exit()

# ==========================
# 🔹 دالة تحسين الصورة (مُحسّنة لجميع الألوان والتباين)
# ==========================
def preprocess_image(img):
    """تجمع بين تحسينات HSV و LAB لزيادة التباين اللوني والسطوع."""
    # تحسين HSV (السطوع والتشبع)
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8)) # زيادة التباين اللوني
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)
    
    # تحسين LAB (لتحسين الفقاعات البيضاء والحدود)
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    # دمج التحسينين (60% LAB + 40% HSV)
    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# 🔹 دالة تقسيم الصورة الطويلة
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        
        # ضبط الشريحة الأخيرة
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = h - slice_height
            if y_start < 0: y_start = 0
            y_end = h 
        
        slices.append((image[y_start:y_end, :].copy(), y_start))
        
        if y_end == h:
            break
            
        y_start += (slice_height - overlap)
        if y_start >= h:
             break
             
    return slices

# ==========================
# 🔹 IOU لحساب التداخل
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# 🔹 دالة الدمج والتنظيف القوية
# ==========================
def merge_and_clean_boxes(boxes_raw, merge_iou_thresh=0.4): # عتبة دمج منخفضة للفقاعات المقطوعة
    """
    تقوم بدمج الأجزاء المكتشفة المتداخلة بشدة، ثم تنظيف النتائج النهائية.
    """
    if not boxes_raw: return []
    
    boxes = np.array(boxes_raw, dtype=np.float32)
    merged_boxes = []
    processed = set() 

    # المرحلة 1: الدمج العدواني (Aggressive Merging)
    for i in range(len(boxes)):
        if i in processed: continue
        
        current_box = boxes[i]
        overlaps_indices = [i] 
        
        for j in range(i + 1, len(boxes)):
            if j in processed: continue
            
            iou = box_iou(current_box, boxes[j])
            
            if iou > merge_iou_thresh: # الدمج إذا كان التداخل 40% أو أكثر
                overlaps_indices.append(j)
        
        all_overlapping_boxes = boxes[overlaps_indices]
        
        # إنشاء مستطيل محيط يغطي كل الأجزاء
        x1_min = np.min(all_overlapping_boxes[:, 0])
        y1_min = np.min(all_overlapping_boxes[:, 1])
        x2_max = np.max(all_overlapping_boxes[:, 2])
        y2_max = np.max(all_overlapping_boxes[:, 3])
        
        merged_boxes.append((x1_min, y1_min, x2_max, y2_max))
        
        for idx in overlaps_indices:
            processed.add(idx)
            
    # المرحلة 2: تطبيق NMS خفيف لتنظيف التكرار العارض
    final_clean_boxes = []
    if merged_boxes:
        merged_boxes_np = np.array(merged_boxes, dtype=np.float32)
        suppressed = np.zeros(len(merged_boxes_np), dtype=bool)
        
        for i in range(len(merged_boxes_np)):
            if suppressed[i]: continue
            
            final_clean_boxes.append(merged_boxes_np[i].tolist())
            
            for j in range(i + 1, len(merged_boxes_np)):
                if suppressed[j]: continue
                
                iou = box_iou(merged_boxes_np[i], merged_boxes_np[j])
                # عتبة IOU منخفضة جداً (0.1) للحذف
                if iou > 0.1: 
                    suppressed[j] = True

    return final_clean_boxes

# ==========================
# 🔹 المعالجة الرئيسية
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"Error: Image folder not found at '{image_folder}'")
    exit()
    
image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"⚠️ لم يتمكن من قراءة الصورة: {img_path}")
        continue

    # 1. تحسين الصورة
    enhanced_img = preprocess_image(image)

    h, w, _ = image.shape
    boxes = [] # قائمة لحفظ كل الاكتشافات

    # 2. تقسيم الصورة
    slices = slice_image(enhanced_img, overlap=SLICE_OVERLAP) if h > SLICE_HEIGHT else [(enhanced_img, 0)]
    
    for slice_img, offset_y in slices:
        # نمرر numpy array مباشرة للموديل
        results = model(slice_img, imgsz=1280, conf=CONFIDENCE_THRESHOLD, verbose=False) 
        
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.conf.cpu().numpy()):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    
                    x1, y1, x2, y2 = box.tolist()
                    
                    # تعديل الإحداثيات بالنسبة للصورة الأصلية
                    x1, y1, x2, y2 = x1, y1 + offset_y, x2, y2 + offset_y
                    
                    if (x2 - x1) * (y2 - y1) < 2000: # تجاهل الفقاعات الصغيرة جدًا
                        continue
                        
                    # نجمع كل الاكتشافات دون تصفية
                    boxes.append((x1, y1, x2, y2))
    
    # 3. تطبيق دالة الدمج والتنظيف مرة واحدة
    clean_boxes = merge_and_clean_boxes(boxes, merge_iou_thresh=0.4) 

    bubbles = []
    for x1, y1, x2, y2 in clean_boxes:
        # نحول المستطيل المحيط إلى مضلع رباعي (Path)
        bubbles.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])

    key = f"{idx:02d}_mask"
    # تحويل الإحداثيات إلى أعداد صحيحة
    all_bubbles[key] = [{"id": i + 1, "points": [[int(round(x)), int(round(y))] for x, y in b]} for i, b in enumerate(bubbles)]
    
    print(f"✅ Processed {img_file}, found {len(bubbles)} clean bubbles.")

# ==========================
# 🔹 حفظ النتائج إلى JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\n🎉 All unique bubbles saved to:\n{output_path}")


; ؟؟؟؟ افضل واحد حتي النتائج##########################
##############
##############################

from ultralytics import YOLO
import os
import json
import cv2
import numpy as np
import math

# ==========================
# 🔹 إعداد المسارات والنموذج
# ==========================
# 🚨 استخدم النموذج الأكثر دقة المُشار إليه في بيانات مشروعك
MODEL_FILENAME = "comic-speech-bubble-detector.pt" # أو "yolov8m.pt"
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

# إعدادات الحساسية
CONFIDENCE_THRESHOLD = 0.15  # تم خفضه لاكتشاف الفقاعات الملونة والغامقة
SLICE_OVERLAP = 300          # تداخل جيد للصور الطويلة
SLICE_HEIGHT = 2500

try:
    model = YOLO(model_path)
    print(f"✅ تم تحميل النموذج: {MODEL_FILENAME}")
except Exception as e:
    print(f"FATAL ERROR: Failed to load YOLO model from {model_path}. Error: {e}")
    exit()

# ==========================
# 🔹 دالة تحسين الصورة (مُحسّنة لجميع الألوان والتباين)
# ==========================
def preprocess_image(img):
    """تجمع بين تحسينات HSV و LAB لزيادة التباين اللوني والسطوع."""
    # تحسين HSV (السطوع والتشبع)
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8)) # زيادة التباين اللوني
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)
    
    # تحسين LAB (لتحسين الفقاعات البيضاء والحدود)
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    # دمج التحسينين (60% LAB + 40% HSV)
    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# 🔹 دالة تقسيم الصورة الطويلة
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        
        # ضبط الشريحة الأخيرة
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = h - slice_height
            if y_start < 0: y_start = 0
            y_end = h 
        
        slices.append((image[y_start:y_end, :].copy(), y_start))
        
        if y_end == h:
            break
            
        y_start += (slice_height - overlap)
        if y_start >= h:
             break
             
    return slices

# ==========================
# 🔹 IOU لحساب التداخل
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# 🔹 دالة الدمج والتنظيف القوية
# ==========================
def merge_and_clean_boxes(boxes_raw, merge_iou_thresh=0.4): # عتبة دمج منخفضة للفقاعات المقطوعة
    """
    تقوم بدمج الأجزاء المكتشفة المتداخلة بشدة، ثم تنظيف النتائج النهائية.
    """
    if not boxes_raw: return []
    
    boxes = np.array(boxes_raw, dtype=np.float32)
    merged_boxes = []
    processed = set() 

    # المرحلة 1: الدمج العدواني (Aggressive Merging)
    for i in range(len(boxes)):
        if i in processed: continue
        
        current_box = boxes[i]
        overlaps_indices = [i] 
        
        for j in range(i + 1, len(boxes)):
            if j in processed: continue
            
            iou = box_iou(current_box, boxes[j])
            
            if iou > merge_iou_thresh: # الدمج إذا كان التداخل 40% أو أكثر
                overlaps_indices.append(j)
        
        all_overlapping_boxes = boxes[overlaps_indices]
        
        # إنشاء مستطيل محيط يغطي كل الأجزاء
        x1_min = np.min(all_overlapping_boxes[:, 0])
        y1_min = np.min(all_overlapping_boxes[:, 1])
        x2_max = np.max(all_overlapping_boxes[:, 2])
        y2_max = np.max(all_overlapping_boxes[:, 3])
        
        merged_boxes.append((x1_min, y1_min, x2_max, y2_max))
        
        for idx in overlaps_indices:
            processed.add(idx)
            
    # المرحلة 2: تطبيق NMS خفيف لتنظيف التكرار العارض
    final_clean_boxes = []
    if merged_boxes:
        merged_boxes_np = np.array(merged_boxes, dtype=np.float32)
        suppressed = np.zeros(len(merged_boxes_np), dtype=bool)
        
        for i in range(len(merged_boxes_np)):
            if suppressed[i]: continue
            
            final_clean_boxes.append(merged_boxes_np[i].tolist())
            
            for j in range(i + 1, len(merged_boxes_np)):
                if suppressed[j]: continue
                
                iou = box_iou(merged_boxes_np[i], merged_boxes_np[j])
                # عتبة IOU منخفضة جداً (0.1) للحذف
                if iou > 0.1: 
                    suppressed[j] = True

    return final_clean_boxes

# ==========================
# 🔹 المعالجة الرئيسية
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"Error: Image folder not found at '{image_folder}'")
    exit()
    
image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"⚠️ لم يتمكن من قراءة الصورة: {img_path}")
        continue

    # 1. تحسين الصورة
    enhanced_img = preprocess_image(image)

    h, w, _ = image.shape
    boxes = [] # قائمة لحفظ كل الاكتشافات

    # 2. تقسيم الصورة
    slices = slice_image(enhanced_img, overlap=SLICE_OVERLAP) if h > SLICE_HEIGHT else [(enhanced_img, 0)]
    
    for slice_img, offset_y in slices:
        # نمرر numpy array مباشرة للموديل
        results = model(slice_img, imgsz=1280, conf=CONFIDENCE_THRESHOLD, verbose=False) 
        
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.conf.cpu().numpy()):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    
                    x1, y1, x2, y2 = box.tolist()
                    
                    # تعديل الإحداثيات بالنسبة للصورة الأصلية
                    x1, y1, x2, y2 = x1, y1 + offset_y, x2, y2 + offset_y
                    
                    if (x2 - x1) * (y2 - y1) < 2000: # تجاهل الفقاعات الصغيرة جدًا
                        continue
                        
                    # نجمع كل الاكتشافات دون تصفية
                    boxes.append((x1, y1, x2, y2))
    
    # 3. تطبيق دالة الدمج والتنظيف مرة واحدة
    clean_boxes = merge_and_clean_boxes(boxes, merge_iou_thresh=0.4) 

    bubbles = []
    for x1, y1, x2, y2 in clean_boxes:
        # نحول المستطيل المحيط إلى مضلع رباعي (Path)
        bubbles.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])

    key = f"{idx:02d}_mask"
    # تحويل الإحداثيات إلى أعداد صحيحة
    all_bubbles[key] = [{"id": i + 1, "points": [[int(round(x)), int(round(y))] for x, y in b]} for i, b in enumerate(bubbles)]
    
    print(f"✅ Processed {img_file}, found {len(bubbles)} clean bubbles.")

# ==========================
# 🔹 حفظ النتائج إلى JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\n🎉 All unique bubbles saved to:\n{output_path}")

##############
; افضل من السابق 

from ultralytics import YOLO
import os
import json
import cv2
import numpy as np

# ==========================
# 🔹 إعداد المسارات والنموذج
# ==========================
MODEL_FILENAME = "comic-speech-bubble-detector.pt"
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

# إعدادات الحساسية
CONFIDENCE_THRESHOLD = 0.15
SLICE_OVERLAP = 300
SLICE_HEIGHT = 2500

# تحميل الموديل
try:
    model = YOLO(model_path)
    print(f"✅ تم تحميل النموذج: {MODEL_FILENAME}")
except Exception as e:
    print(f"❌ خطأ أثناء تحميل النموذج من {model_path}: {e}")
    exit()

# ==========================
# 🔹 تحسين الصورة
# ==========================
def preprocess_image(img):
    """
    تحسين الصورة لزيادة وضوح الفقاعات حتى ذات الألوان الغامقة أو الشفافة.
    """
    # تحويل إلى HSV لزيادة السطوع والتباين
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)

    # تحسين LAB لزيادة التباين في الحواف البيضاء والخلفيات الغامقة
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    # دمج LAB + HSV لنتيجة أكثر توازناً
    combined = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)

    # تصحيح الجاما (Gamma correction) لتوضيح الألوان الغامقة والشفافة
    gamma = 1.5  # يمكنك تعديلها بين 1.3 و 1.8 حسب الصور
    inv_gamma = 1.0 / gamma
    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in np.arange(256)]).astype("uint8")
    final = cv2.LUT(combined, table)

    return final

# ==========================
# 🔹 تقسيم الصورة الطويلة
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = max(0, h - slice_height)
            y_end = h
        slices.append((image[y_start:y_end, :].copy(), y_start))
        if y_end == h:
            break
        y_start += (slice_height - overlap)
    return slices

# ==========================
# 🔹 IOU لحساب التداخل
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# 🔹 دمج وتنظيف المربعات
# ==========================
def merge_and_clean_boxes(boxes_raw, merge_iou_thresh=0.4):
    if not boxes_raw:
        return []
    boxes = np.array(boxes_raw, dtype=np.float32)
    merged_boxes, processed = [], set()

    for i in range(len(boxes)):
        if i in processed:
            continue
        current_box = boxes[i]
        overlaps_indices = [i]
        for j in range(i + 1, len(boxes)):
            if j in processed:
                continue
            if box_iou(current_box, boxes[j]) > merge_iou_thresh:
                overlaps_indices.append(j)
        all_overlapping_boxes = boxes[overlaps_indices]
        x1_min = np.min(all_overlapping_boxes[:, 0])
        y1_min = np.min(all_overlapping_boxes[:, 1])
        x2_max = np.max(all_overlapping_boxes[:, 2])
        y2_max = np.max(all_overlapping_boxes[:, 3])
        merged_boxes.append((x1_min, y1_min, x2_max, y2_max))
        for idx in overlaps_indices:
            processed.add(idx)

    # تنظيف إضافي
    final_clean_boxes = []
    suppressed = np.zeros(len(merged_boxes), dtype=bool)
    for i in range(len(merged_boxes)):
        if suppressed[i]:
            continue
        final_clean_boxes.append(merged_boxes[i])
        for j in range(i + 1, len(merged_boxes)):
            if suppressed[j]:
                continue
            if box_iou(merged_boxes[i], merged_boxes[j]) > 0.1:
                suppressed[j] = True
    return final_clean_boxes

# ==========================
# 🔹 المعالجة الرئيسية
# ==========================
all_bubbles = {}
if not os.path.exists(image_folder):
    print(f"❌ لم يتم العثور على مجلد الصور: {image_folder}")
    exit()

image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"⚠️ لم يتمكن من قراءة الصورة: {img_path}")
        continue

    enhanced_img = preprocess_image(image)
    h, w, _ = image.shape
    boxes = []
    slices = slice_image(enhanced_img) if h > SLICE_HEIGHT else [(enhanced_img, 0)]

    for slice_img, offset_y in slices:
        results = model(slice_img, imgsz=1280, conf=CONFIDENCE_THRESHOLD, verbose=False)
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.conf.cpu().numpy()):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    x1, y1, x2, y2 = box.tolist()
                    y1 += offset_y
                    y2 += offset_y
                    if (x2 - x1) * (y2 - y1) < 1500:
                        continue
                    boxes.append((x1, y1, x2, y2))

    clean_boxes = merge_and_clean_boxes(boxes, merge_iou_thresh=0.4)
    bubbles = []
    for x1, y1, x2, y2 in clean_boxes:
        bubbles.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])

    key = f"{idx:02d}_mask"
    all_bubbles[key] = [{"id": i + 1, "points": [[int(x), int(y)] for x, y in b]} for i, b in enumerate(bubbles)]
    print(f"✅ {img_file}: {len(bubbles)} فقاعة مكتشفة بعد التحسين.")

# ==========================
# 🔹 حفظ النتائج
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\n🎉 تم حفظ جميع الفقاعات في:\n{output_path}")

؟؟؟؟ دقه ممتازه3#####################
####################
######################












from ultralytics import YOLO
import easyocr
import os
import json
import cv2
import numpy as np
from shapely.geometry import Polygon

# ==========================
# 🔹 Setup Paths and Model
# ==========================
MODEL_FILENAME = "comic-speech-bubble-detector.pt"  # Specialized model for speech bubbles
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

# Sensitivity settings
CONFIDENCE_THRESHOLD = 0.15  # Lowered to detect colored and dark bubbles
SLICE_OVERLAP = 300          # Good overlap for long images
SLICE_HEIGHT = 2500

try:
    model = YOLO(model_path)
    print(f"✅ Loaded model: {MODEL_FILENAME}")
except Exception as e:
    print(f"FATAL ERROR: Failed to load YOLO model from {model_path}. Error: {e}")
    exit()

# Load EasyOCR
try:
    ocr = easyocr.Reader(['en', 'ja'], gpu=True)  # Support English and Japanese
except Exception as e:
    print(f"⚠️ Falling back to CPU for EasyOCR: {e}")
    ocr = easyocr.Reader(['en', 'ja'], gpu=False)

# ==========================
# 🔹 Image Enhancement (Optimized for all colors and contrast)
# ==========================
def preprocess_image(img):
    """Combines HSV and LAB enhancements to increase color and brightness contrast."""
    # HSV enhancement (brightness and saturation)
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))  # Increase color contrast
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)
    
    # LAB enhancement (for white bubbles and edges)
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    # Combine enhancements (60% LAB + 40% HSV)
    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# 🔹 Slice Long Image
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = max(0, h - slice_height)
            y_end = h
        slices.append((image[y_start:y_end, :].copy(), y_start))
        if y_end == h:
            break
        y_start += (slice_height - overlap)
    return slices

# ==========================
# 🔹 IOU for Overlap Calculation
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# 🔹 Merge and Clean Boxes Strongly
# ==========================
def merge_and_clean_boxes(boxes_raw, merge_iou_thresh=0.4):  # Low merge threshold for sliced bubbles
    """
    Merges heavily overlapping detected parts, then cleans the final results.
    """
    if not boxes_raw: return []
    
    boxes = np.array(boxes_raw, dtype=np.float32)
    merged_boxes = []
    processed = set() 

    # Phase 1: Aggressive Merging
    for i in range(len(boxes)):
        if i in processed: continue
        
        current_box = boxes[i]
        overlaps_indices = [i] 
        
        for j in range(i + 1, len(boxes)):
            if j in processed: continue
            
            iou = box_iou(current_box, boxes[j])
            
            if iou > merge_iou_thresh:  # Merge if overlap is 40% or more
                overlaps_indices.append(j)
        
        all_overlapping_boxes = boxes[overlaps_indices]
        
        # Create bounding rectangle covering all parts
        x1_min = np.min(all_overlapping_boxes[:, 0])
        y1_min = np.min(all_overlapping_boxes[:, 1])
        x2_max = np.max(all_overlapping_boxes[:, 2])
        y2_max = np.max(all_overlapping_boxes[:, 3])
        
        merged_boxes.append((x1_min, y1_min, x2_max, y2_max))
        
        for idx in overlaps_indices:
            processed.add(idx)
            
    # Phase 2: Light NMS for incidental duplicate cleaning
    final_clean_boxes = []
    if merged_boxes:
        merged_boxes_np = np.array(merged_boxes, dtype=np.float32)
        suppressed = np.zeros(len(merged_boxes_np), dtype=bool)
        
        for i in range(len(merged_boxes_np)):
            if suppressed[i]: continue
            
            final_clean_boxes.append(merged_boxes_np[i].tolist())
            
            for j in range(i + 1, len(merged_boxes_np)):
                if suppressed[j]: continue
                
                iou = box_iou(merged_boxes_np[i], merged_boxes_np[j])
                # Very low IOU threshold (0.1) for deletion
                if iou > 0.1: 
                    suppressed[j] = True

    return final_clean_boxes

# ==========================
# 🔹 Main Processing
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"Error: Image folder not found at '{image_folder}'")
    exit()
    
image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"⚠️ Failed to read image: {img_path}")
        continue

    # 1. Preprocess image
    enhanced_img = preprocess_image(image)

    h, w, _ = image.shape
    boxes = [] # List to store all detections

    # 2. Slice image
    slices = slice_image(enhanced_img, overlap=SLICE_OVERLAP) if h > SLICE_HEIGHT else [(enhanced_img, 0)]
    
    for slice_img, offset_y in slices:
        # Pass numpy array directly to model
        results = model(slice_img, imgsz=1280, conf=CONFIDENCE_THRESHOLD, verbose=False) 
        
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.conf.cpu().numpy()):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    
                    x1, y1, x2, y2 = box.tolist()
                    
                    # Adjust coordinates relative to original image
                    x1, y1, x2, y2 = x1, y1 + offset_y, x2, y2 + offset_y
                    
                    if (x2 - x1) * (y2 - y1) < 2000: # Ignore very small bubbles
                        continue
                        
                    # Collect all detections without filtering
                    boxes.append((x1, y1, x2, y2))
    
    # 3. Apply merge and clean function once
    clean_boxes = merge_and_clean_boxes(boxes, merge_iou_thresh=0.4) 

    bubbles = []
    for x1, y1, x2, y2 in clean_boxes:
        # Convert bounding rectangle to quadrilateral (Path)
        bubbles.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])

    key = f"{idx:02d}_mask"
    # Convert coordinates to integers
    all_bubbles[key] = [{"id": i + 1, "points": [[int(round(x)), int(round(y))] for x, y in b]} for i, b in enumerate(bubbles)]
    
    print(f"✅ Processed {img_file}, found {len(bubbles)} clean bubbles.")

# ==========================
# 🔹 Save Results to JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\n🎉 All unique bubbles saved to:\n{output_path}")  


################كود ناج تلالته قدر يشوف الفقاعه الصراخ




from ultralytics import YOLO
import easyocr
import os
import json
import cv2
import numpy as np
import re

# ==========================
# 🔹 Setup Paths and Model
# ==========================
MODEL_FILENAME = "comic-speech-bubble-detector.pt"
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

CONFIDENCE_THRESHOLD = 0.05  # Lowered for more sensitive detection
SLICE_OVERLAP = 300
SLICE_HEIGHT = 2500

try:
    model = YOLO(model_path)
    print(f"✅ Loaded model: {MODEL_FILENAME}")
except Exception as e:
    print(f"FATAL ERROR: Failed to load YOLO model from {model_path}. Error: {e}")
    exit()

try:
    reader = easyocr.Reader(['en','ja','ko'], gpu=True)
except Exception as e:
    print(f"⚠️ EasyOCR GPU failed, fallback CPU: {e}")
    reader = easyocr.Reader(['en','ja','ko'], gpu=False)

# ==========================
# 🔹 Image Preprocessing
# ==========================
def preprocess_image(img):
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)

    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# 🔹 Slice Image
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = max(0, h - slice_height)
            y_end = h
        slices.append((image[y_start:y_end, :].copy(), y_start))
        if y_end == h:
            break
        y_start += (slice_height - overlap)
    return slices

# ==========================
# 🔹 IOU Function
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# 🔹 Merge and Clean Boxes
# ==========================
def merge_and_clean_boxes(boxes_raw, merge_iou_thresh=0.4):
    if not boxes_raw: return []
    boxes = np.array(boxes_raw, dtype=np.float32)
    merged_boxes = []
    processed = set()
    for i in range(len(boxes)):
        if i in processed: continue
        current_box = boxes[i]
        overlaps_indices = [i]
        for j in range(i + 1, len(boxes)):
            if j in processed: continue
            if box_iou(current_box, boxes[j]) > merge_iou_thresh:
                overlaps_indices.append(j)
        all_boxes = boxes[overlaps_indices]
        x1_min = np.min(all_boxes[:,0])
        y1_min = np.min(all_boxes[:,1])
        x2_max = np.max(all_boxes[:,2])
        y2_max = np.max(all_boxes[:,3])
        merged_boxes.append((x1_min, y1_min, x2_max, y2_max))
        for idx in overlaps_indices: processed.add(idx)
    # Light NMS
    final_clean_boxes = []
    merged_boxes_np = np.array(merged_boxes, dtype=np.float32)
    suppressed = np.zeros(len(merged_boxes_np), dtype=bool)
    for i in range(len(merged_boxes_np)):
        if suppressed[i]: continue
        final_clean_boxes.append(merged_boxes_np[i].tolist())
        for j in range(i+1,len(merged_boxes_np)):
            if suppressed[j]: continue
            if box_iou(merged_boxes_np[i], merged_boxes_np[j]) > 0.1:
                suppressed[j] = True
    return final_clean_boxes

# ==========================
# 🔹 OCR / Text Verification
# ==========================
def has_meaningful_text(image, box, reader):
    x1, y1, x2, y2 = map(int, box)
    x1, y1 = max(0, x1-5), max(0, y1-5)
    x2, y2 = min(image.shape[1], x2+5), min(image.shape[0], y2+5)
    if x2<=x1 or y2<=y1: return True  # Always allow
    
    crop = image[y1:y2, x1:x2]
    if crop.size == 0: return True

    gray_crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    clahe_crop = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4,4))
    processed_crop = clahe_crop.apply(gray_crop)

    try:
        results = reader.readtext(processed_crop, detail=0)
    except:
        results = []

    # Always allow empty or faint bubbles
    if not results: return True
    for text in results:
        cleaned = re.sub(r'\s+','',text)
        if len(cleaned) > 1: return True
        if re.search(r'(\.{2,}|!+|\?+)', cleaned): return True
    return True

# ==========================
# 🔹 Main Processing
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"Error: Image folder not found at '{image_folder}'")
    exit()

image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg",".png",".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"⚠️ Failed to read image: {img_path}")
        continue

    enhanced_img = preprocess_image(image)
    h, w, _ = image.shape
    boxes = []

    slices = slice_image(enhanced_img) if h>SLICE_HEIGHT else [(enhanced_img,0)]
    for slice_img, offset_y in slices:
        results = model(slice_img, imgsz=1280, conf=CONFIDENCE_THRESHOLD, verbose=False)
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.conf.cpu().numpy()):
                    if score < CONFIDENCE_THRESHOLD: continue
                    x1,y1,x2,y2 = box.tolist()
                    y1 += offset_y
                    y2 += offset_y
                    if (x2-x1)*(y2-y1) < 2000: continue
                    boxes.append((x1,y1,x2,y2))

    clean_boxes = merge_and_clean_boxes(boxes, merge_iou_thresh=0.4)
    bubbles = []
    for x1,y1,x2,y2 in clean_boxes:
        if has_meaningful_text(image, (x1,y1,x2,y2), reader):
            bubbles.append([[x1,y1],[x2,y1],[x2,y2],[x1,y2]])

    key = f"{idx:02d}_mask"
    all_bubbles[key] = [{"id":i+1, "points":[[int(round(x)),int(round(y))] for x,y in b]} for i,b in enumerate(bubbles)]
    print(f"✅ Processed {img_file}, found {len(bubbles)} bubbles.")

# ==========================
# 🔹 Save JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path,"w",encoding="utf-8") as f:
    json.dump(all_bubbles,f,indent=2)

print(f"\n🎉 All bubbles saved to: {output_path}")

@#############تم اكتشفا الفقاعه التي لونها ازرق الكود رقم 4














الكود كويس جدا
بس في باثات معموله مرتين
حاول تحل المشكله دي بحيث كل نص عليه باث واحد بس حوالين الفقاعه الباث الكبير يعني
بس عامتا الكود جمييل جدا وفيه كل اللي انا عايزه وبيكتشف الفقاعات باعلي مستوي
from ultralytics import YOLO
import os
import json
import cv2
import numpy as np
import re
from PIL import Image

# محاولة استيراد MangaOCR، وإلا استخدام EasyOCR
try:
    from manga_ocr import MangaOcr
    USE_MANGA_OCR = True
    print("✅ Using MangaOCR for text validation (specialized for manga).")
except ImportError:
    import easyocr
    USE_MANGA_OCR = False
    print("⚠️ MangaOCR not found, falling back to EasyOCR. Install with: pip install manga-ocr")

# ==========================
# 🔹 إعداد المسارات والنموذج
# ==========================
MODEL_FILENAME = "comic-speech-bubble-detector.pt"  # يمكن استخدام yolov8m-seg.pt لـ segmentation
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

# إعدادات الحساسية
CONFIDENCE_THRESHOLD = 0.05  # منخفضة لكشف الفقاعات الزرقاء/الصعبة
IOU_THRESHOLD = 0.5  # عتبة NMS قياسية
SLICE_OVERLAP = 300
SLICE_HEIGHT = 2500
MIN_BUBBLE_AREA = 2000  # تجاهل الفقاعات الصغيرة جدًا

# تحميل النموذج
try:
    model = YOLO(model_path)
    print(f"✅ تم تحميل النموذج: {MODEL_FILENAME}")
except Exception as e:
    print(f"❌ خطأ أثناء تحميل النموذج: {e}")
    exit()

# تحميل OCR
if USE_MANGA_OCR:
    try:
        ocr = MangaOcr()
    except Exception as e:
        print(f"⚠️ Failed to load MangaOCR: {e}. Falling back to EasyOCR.")
        USE_MANGA_OCR = False
        ocr = easyocr.Reader(['en', 'ja', 'ko'], gpu=True)
else:
    try:
        ocr = easyocr.Reader(['en', 'ja', 'ko'], gpu=True)
    except Exception as e:
        print(f"⚠️ EasyOCR GPU failed, using CPU: {e}")
        ocr = easyocr.Reader(['en', 'ja', 'ko'], gpu=False)

# ==========================
# 🔹 تحسين الصورة
# ==========================
def preprocess_image(img):
    """تحسين الصورة لزيادة وضوح الفقاعات."""
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)

    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# 🔹 تقسيم الصورة الطويلة
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    """تقسم الصورة الطويلة إلى شرائح مع تداخل."""
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = max(0, h - slice_height)
            y_end = h
        slices.append((image[y_start:y_end, :].copy(), y_start))
        if y_end == h:
            break
        y_start += (slice_height - overlap)
    return slices

# ==========================
# 🔹 التحقق من النص المعنوي بـ OCR
# ==========================
def has_meaningful_text(image, box, ocr):
    """التحقق مما إذا كانت الفقاعة تحتوي على نص معنوي."""
    x1, y1, x2, y2 = map(int, box)
    x1, y1 = max(0, x1-5), max(0, y1-5)
    x2, y2 = min(image.shape[1], x2+5), min(image.shape[0], y2+5)
    if x2 <= x1 or y2 <= y1:
        return False

    crop = image[y1:y2, x1:x2]
    if crop.size == 0:
        return False

    # تحسين المقطع لـ OCR
    gray_crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    clahe_crop = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4,4))
    processed_crop = clahe_crop.apply(gray_crop)

    try:
        if USE_MANGA_OCR:
            # تحويل إلى PIL.Image لـ MangaOCR
            pil_image = Image.fromarray(processed_crop)
            text = ocr(pil_image)
        else:
            # استخدام EasyOCR
            results = ocr.readtext(processed_crop, detail=0)
            text = ' '.join(results) if results else ''
    except Exception as e:
        print(f"⚠️ OCR failed for box [{x1}, {y1}, {x2}, {y2}]: {e}")
        return False

    # التحقق من النص المعنوي
    cleaned = re.sub(r'\s+', '', text) if text else ''
    if len(cleaned) > 1 or re.search(r'(\.{2,}|!+|\?+)', cleaned):
        return True
    return False

# ==========================
# 🔹 المعالجة الرئيسية
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"❌ لم يتم العثور على مجلد الصور: {image_folder}")
    exit()

image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"⚠️ فشل قراءة الصورة: {img_path}")
        continue

    # تحسين الصورة
    enhanced_img = preprocess_image(image)
    h, w, _ = image.shape
    all_boxes = []

    # تقسيم الصورة إذا كانت طويلة
    slices = slice_image(enhanced_img) if h > SLICE_HEIGHT else [(enhanced_img, 0)]
    for slice_img, offset_y in slices:
        # كشف الفقاعات باستخدام YOLO
        results = model(slice_img, imgsz=640, conf=CONFIDENCE_THRESHOLD, iou=IOU_THRESHOLD, verbose=False)
        for r in results:
            if r.boxes:
                boxes = r.boxes.xyxy.cpu().numpy()
                scores = r.boxes.conf.cpu().numpy()
                for box, score in zip(boxes, scores):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    x1, y1, x2, y2 = box.tolist()
                    y1 += offset_y
                    y2 += offset_y
                    area = (x2 - x1) * (y2 - y1)
                    if area < MIN_BUBBLE_AREA:
                        continue
                    all_boxes.append([x1, y1, x2, y2])

    # تصفية الفقاعات باستخدام OCR
    valid_bubbles = []
    for box in all_boxes:
        if has_meaningful_text(image, box, ocr):
            valid_bubbles.append([[box[0], box[1]], [box[2], box[1]], [box[2], box[3]], [box[0], box[3]]])

    # إنشاء مفتاح للـ JSON
    key = f"{idx:02d}_mask"
    all_bubbles[key] = [{"id": i + 1, "points": [[int(round(x)), int(round(y))] for x, y in b]} for i, b in enumerate(valid_bubbles)]
    print(f"✅ Processed {img_file}, found {len(valid_bubbles)} valid bubbles.")

# ==========================
# 🔹 حفظ النتائج إلى JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\n🎉 All unique bubbles saved to:\n{output_path}")


|||اكثر دقه بس باثات كتير




from ultralytics import YOLO
import os
import json
import cv2
import numpy as np
import re
from PIL import Image

# محاولة استيراد MangaOCR، وإلا استخدام EasyOCR
try:
    from manga_ocr import MangaOcr
    USE_MANGA_OCR = True
    print("✅ Using MangaOCR for text validation (specialized for manga).")
except ImportError:
    import easyocr
    USE_MANGA_OCR = False
    print("⚠️ MangaOCR not found, falling back to EasyOCR. Install with: pip install manga-ocr")

# ==========================
# 🔹 إعداد المسارات والنموذج
# ==========================
MODEL_FILENAME = "comic-speech-bubble-detector.pt"  # يمكن استخدام yolov8m-seg.pt لـ segmentation
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

# إعدادات الحساسية
CONFIDENCE_THRESHOLD = 0.05  # منخفضة لكشف الفقاعات الزرقاء/الصعبة
IOU_THRESHOLD = 0.5  # عتبة NMS قياسية
SLICE_OVERLAP = 300
SLICE_HEIGHT = 2500
MIN_BUBBLE_AREA = 2000  # تجاهل الفقاعات الصغيرة جدًا

# تحميل النموذج
try:
    model = YOLO(model_path)
    print(f"✅ تم تحميل النموذج: {MODEL_FILENAME}")
except Exception as e:
    print(f"❌ خطأ أثناء تحميل النموذج: {e}")
    exit()

# تحميل OCR
if USE_MANGA_OCR:
    try:
        ocr = MangaOcr()
    except Exception as e:
        print(f"⚠️ Failed to load MangaOCR: {e}. Falling back to EasyOCR.")
        USE_MANGA_OCR = False
        ocr = easyocr.Reader(['en', 'ja', 'ko'], gpu=True)
else:
    try:
        ocr = easyocr.Reader(['en', 'ja', 'ko'], gpu=True)
    except Exception as e:
        print(f"⚠️ EasyOCR GPU failed, using CPU: {e}")
        ocr = easyocr.Reader(['en', 'ja', 'ko'], gpu=False)

# ==========================
# 🔹 تحسين الصورة
# ==========================
def preprocess_image(img):
    """تحسين الصورة لزيادة وضوح الفقاعات."""
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)

    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# 🔹 تقسيم الصورة الطويلة
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    """تقسم الصورة الطويلة إلى شرائح مع تداخل."""
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = max(0, h - slice_height)
            y_end = h
        slices.append((image[y_start:y_end, :].copy(), y_start))
        if y_end == h:
            break
        y_start += (slice_height - overlap)
    return slices

# ==========================
# 🔹 IOU لحساب التداخل
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# 🔹 دمج وتنظيف المربعات (لتجنب التكرار)
# ==========================
def merge_and_clean_boxes(boxes_raw, scores_raw, merge_iou_thresh=0.5):
    if not boxes_raw:
        return [], []
    boxes = np.array(boxes_raw, dtype=np.float32)
    scores = np.array(scores_raw, dtype=np.float32)
    merged_boxes = []
    merged_scores = []
    processed = set()

    for i in range(len(boxes)):
        if i in processed:
            continue
        current_box = boxes[i]
        current_score = scores[i]
        overlaps_indices = [i]
        for j in range(i + 1, len(boxes)):
            if j in processed:
                continue
            if box_iou(current_box, boxes[j]) > merge_iou_thresh:
                overlaps_indices.append(j)
        all_overlapping_boxes = boxes[overlaps_indices]
        x1_min = np.min(all_overlapping_boxes[:, 0])
        y1_min = np.min(all_overlapping_boxes[:, 1])
        x2_max = np.max(all_overlapping_boxes[:, 2])
        y2_max = np.max(all_overlapping_boxes[:, 3])
        merged_boxes.append([x1_min, y1_min, x2_max, y2_max])
        merged_scores.append(np.max(scores[overlaps_indices]))  # اختيار أعلى score
        for idx in overlaps_indices:
            processed.add(idx)

    # تنظيف إضافي بـ NMS خفيف
    final_boxes = []
    final_scores = []
    suppressed = np.zeros(len(merged_boxes), dtype=bool)
    for i in range(len(merged_boxes)):
        if suppressed[i]:
            continue
        final_boxes.append(merged_boxes[i])
        final_scores.append(merged_scores[i])
        for j in range(i + 1, len(merged_boxes)):
            if suppressed[j]:
                continue
            if box_iou(merged_boxes[i], merged_boxes[j]) > 0.3:  # عتبة أقل للتنظيف
                suppressed[j] = True
    return final_boxes, final_scores

# ==========================
# 🔹 التحقق من النص المعنوي بـ OCR
# ==========================
def has_meaningful_text(image, box, ocr):
    """التحقق مما إذا كانت الفقاعة تحتوي على نص معنوي."""
    x1, y1, x2, y2 = map(int, box)
    x1, y1 = max(0, x1-5), max(0, y1-5)
    x2, y2 = min(image.shape[1], x2+5), min(image.shape[0], y2+5)
    if x2 <= x1 or y2 <= y1:
        return False

    crop = image[y1:y2, x1:x2]
    if crop.size == 0:
        return False

    # تحسين المقطع لـ OCR
    gray_crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    clahe_crop = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4,4))
    processed_crop = clahe_crop.apply(gray_crop)

    try:
        if USE_MANGA_OCR:
            # تحويل إلى PIL.Image لـ MangaOCR
            pil_image = Image.fromarray(processed_crop)
            text = ocr(pil_image)
        else:
            # استخدام EasyOCR
            results = ocr.readtext(processed_crop, detail=0)
            text = ' '.join(results) if results else ''
    except Exception as e:
        print(f"⚠️ OCR failed for box [{x1}, {y1}, {x2}, {y2}]: {e}")
        return False

    # التحقق من النص المعنوي
    cleaned = re.sub(r'\s+', '', text) if text else ''
    if len(cleaned) > 1 or re.search(r'(\.{2,}|!+|\?+)', cleaned):
        return True
    return False

# ==========================
# 🔹 المعالجة الرئيسية
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"❌ لم يتم العثور على مجلد الصور: {image_folder}")
    exit()

image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"⚠️ فشل قراءة الصورة: {img_path}")
        continue

    # تحسين الصورة
    enhanced_img = preprocess_image(image)
    h, w, _ = image.shape
    all_boxes = []
    all_scores = []

    # تقسيم الصورة إذا كانت طويلة
    slices = slice_image(enhanced_img) if h > SLICE_HEIGHT else [(enhanced_img, 0)]
    for slice_img, offset_y in slices:
        # كشف الفقاعات باستخدام YOLO
        results = model(slice_img, imgsz=640, conf=CONFIDENCE_THRESHOLD, iou=IOU_THRESHOLD, verbose=False)
        for r in results:
            if r.boxes:
                boxes = r.boxes.xyxy.cpu().numpy()
                scores = r.boxes.conf.cpu().numpy()
                for box, score in zip(boxes, scores):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    x1, y1, x2, y2 = box.tolist()
                    y1 += offset_y
                    y2 += offset_y
                    area = (x2 - x1) * (y2 - y1)
                    if area < MIN_BUBBLE_AREA:
                        continue
                    all_boxes.append([x1, y1, x2, y2])
                    all_scores.append(score)

    # دمج وتنظيف لتجنب التكرار
    clean_boxes, clean_scores = merge_and_clean_boxes(all_boxes, all_scores, merge_iou_thresh=IOU_THRESHOLD)

    # تصفية الفقاعات باستخدام OCR
    valid_bubbles = []
    for box in clean_boxes:
        if has_meaningful_text(image, box, ocr):
            valid_bubbles.append([[box[0], box[1]], [box[2], box[1]], [box[2], box[3]], [box[0], box[3]]])

    # إنشاء مفتاح للـ JSON
    key = f"{idx:02d}_mask"
    all_bubbles[key] = [{"id": i + 1, "points": [[int(round(x)), int(round(y))] for x, y in b]} for i, b in enumerate(valid_bubbles)]
    print(f"✅ Processed {img_file}, found {len(valid_bubbles)} valid bubbles.")

# ==========================
# 🔹 حفظ النتائج إلى JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\n🎉 All unique bubbles saved to:\n{output_path}")

 باثاكت كثير نفس الكلام 




















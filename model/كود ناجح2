from ultralytics import YOLO
import os
import json
import cv2
import numpy as np
import math

# ==========================
# ğŸ”¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬
# ==========================
# ğŸš¨ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙƒØ«Ø± Ø¯Ù‚Ø© Ø§Ù„Ù…ÙØ´Ø§Ø± Ø¥Ù„ÙŠÙ‡ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø´Ø±ÙˆØ¹Ùƒ
MODEL_FILENAME = "comic-speech-bubble-detector.pt" # Ø£Ùˆ "yolov8m.pt"
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©
CONFIDENCE_THRESHOLD = 0.15  # ØªÙ… Ø®ÙØ¶Ù‡ Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ù„ÙˆÙ†Ø© ÙˆØ§Ù„ØºØ§Ù…Ù‚Ø©
SLICE_OVERLAP = 300          # ØªØ¯Ø§Ø®Ù„ Ø¬ÙŠØ¯ Ù„Ù„ØµÙˆØ± Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
SLICE_HEIGHT = 2500

try:
    model = YOLO(model_path)
    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {MODEL_FILENAME}")
except Exception as e:
    print(f"FATAL ERROR: Failed to load YOLO model from {model_path}. Error: {e}")
    exit()

# ==========================
# ğŸ”¹ Ø¯Ø§Ù„Ø© ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© (Ù…ÙØ­Ø³Ù‘Ù†Ø© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†)
# ==========================
def preprocess_image(img):
    """ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† ØªØ­Ø³ÙŠÙ†Ø§Øª HSV Ùˆ LAB Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø§Ù„Ù„ÙˆÙ†ÙŠ ÙˆØ§Ù„Ø³Ø·ÙˆØ¹."""
    # ØªØ­Ø³ÙŠÙ† HSV (Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ´Ø¨Ø¹)
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8)) # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø§Ù„Ù„ÙˆÙ†ÙŠ
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)
    
    # ØªØ­Ø³ÙŠÙ† LAB (Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ ÙˆØ§Ù„Ø­Ø¯ÙˆØ¯)
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    # Ø¯Ù…Ø¬ Ø§Ù„ØªØ­Ø³ÙŠÙ†ÙŠÙ† (60% LAB + 40% HSV)
    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# ğŸ”¹ Ø¯Ø§Ù„Ø© ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        
        # Ø¶Ø¨Ø· Ø§Ù„Ø´Ø±ÙŠØ­Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = h - slice_height
            if y_start < 0: y_start = 0
            y_end = h 
        
        slices.append((image[y_start:y_end, :].copy(), y_start))
        
        if y_end == h:
            break
            
        y_start += (slice_height - overlap)
        if y_start >= h:
             break
             
    return slices

# ==========================
# ğŸ”¹ IOU Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø§Ø®Ù„
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# ğŸ”¹ Ø¯Ø§Ù„Ø© Ø§Ù„Ø¯Ù…Ø¬ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙˆÙŠØ©
# ==========================
def merge_and_clean_boxes(boxes_raw, merge_iou_thresh=0.4): # Ø¹ØªØ¨Ø© Ø¯Ù…Ø¬ Ù…Ù†Ø®ÙØ¶Ø© Ù„Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ù‚Ø·ÙˆØ¹Ø©
    """
    ØªÙ‚ÙˆÙ… Ø¨Ø¯Ù…Ø¬ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ø§Ù„Ù…ØªØ¯Ø§Ø®Ù„Ø© Ø¨Ø´Ø¯Ø©ØŒ Ø«Ù… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©.
    """
    if not boxes_raw: return []
    
    boxes = np.array(boxes_raw, dtype=np.float32)
    merged_boxes = []
    processed = set() 

    # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø¹Ø¯ÙˆØ§Ù†ÙŠ (Aggressive Merging)
    for i in range(len(boxes)):
        if i in processed: continue
        
        current_box = boxes[i]
        overlaps_indices = [i] 
        
        for j in range(i + 1, len(boxes)):
            if j in processed: continue
            
            iou = box_iou(current_box, boxes[j])
            
            if iou > merge_iou_thresh: # Ø§Ù„Ø¯Ù…Ø¬ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ¯Ø§Ø®Ù„ 40% Ø£Ùˆ Ø£ÙƒØ«Ø±
                overlaps_indices.append(j)
        
        all_overlapping_boxes = boxes[overlaps_indices]
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªØ·ÙŠÙ„ Ù…Ø­ÙŠØ· ÙŠØºØ·ÙŠ ÙƒÙ„ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡
        x1_min = np.min(all_overlapping_boxes[:, 0])
        y1_min = np.min(all_overlapping_boxes[:, 1])
        x2_max = np.max(all_overlapping_boxes[:, 2])
        y2_max = np.max(all_overlapping_boxes[:, 3])
        
        merged_boxes.append((x1_min, y1_min, x2_max, y2_max))
        
        for idx in overlaps_indices:
            processed.add(idx)
            
    # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: ØªØ·Ø¨ÙŠÙ‚ NMS Ø®ÙÙŠÙ Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¹Ø§Ø±Ø¶
    final_clean_boxes = []
    if merged_boxes:
        merged_boxes_np = np.array(merged_boxes, dtype=np.float32)
        suppressed = np.zeros(len(merged_boxes_np), dtype=bool)
        
        for i in range(len(merged_boxes_np)):
            if suppressed[i]: continue
            
            final_clean_boxes.append(merged_boxes_np[i].tolist())
            
            for j in range(i + 1, len(merged_boxes_np)):
                if suppressed[j]: continue
                
                iou = box_iou(merged_boxes_np[i], merged_boxes_np[j])
                # Ø¹ØªØ¨Ø© IOU Ù…Ù†Ø®ÙØ¶Ø© Ø¬Ø¯Ø§Ù‹ (0.1) Ù„Ù„Ø­Ø°Ù
                if iou > 0.1: 
                    suppressed[j] = True

    return final_clean_boxes

# ==========================
# ğŸ”¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"Error: Image folder not found at '{image_folder}'")
    exit()
    
image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {img_path}")
        continue

    # 1. ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
    enhanced_img = preprocess_image(image)

    h, w, _ = image.shape
    boxes = [] # Ù‚Ø§Ø¦Ù…Ø© Ù„Ø­ÙØ¸ ÙƒÙ„ Ø§Ù„Ø§ÙƒØªØ´Ø§ÙØ§Øª

    # 2. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø©
    slices = slice_image(enhanced_img, overlap=SLICE_OVERLAP) if h > SLICE_HEIGHT else [(enhanced_img, 0)]
    
    for slice_img, offset_y in slices:
        # Ù†Ù…Ø±Ø± numpy array Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„
        results = model(slice_img, imgsz=1280, conf=CONFIDENCE_THRESHOLD, verbose=False) 
        
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.conf.cpu().numpy()):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    
                    x1, y1, x2, y2 = box.tolist()
                    
                    # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
                    x1, y1, x2, y2 = x1, y1 + offset_y, x2, y2 + offset_y
                    
                    if (x2 - x1) * (y2 - y1) < 2000: # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§
                        continue
                        
                    # Ù†Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø§ÙƒØªØ´Ø§ÙØ§Øª Ø¯ÙˆÙ† ØªØµÙÙŠØ©
                    boxes.append((x1, y1, x2, y2))
    
    # 3. ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø§Ù„Ø© Ø§Ù„Ø¯Ù…Ø¬ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
    clean_boxes = merge_and_clean_boxes(boxes, merge_iou_thresh=0.4) 

    bubbles = []
    for x1, y1, x2, y2 in clean_boxes:
        # Ù†Ø­ÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ·ÙŠÙ„ Ø§Ù„Ù…Ø­ÙŠØ· Ø¥Ù„Ù‰ Ù…Ø¶Ù„Ø¹ Ø±Ø¨Ø§Ø¹ÙŠ (Path)
        bubbles.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])

    key = f"{idx:02d}_mask"
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø¥Ù„Ù‰ Ø£Ø¹Ø¯Ø§Ø¯ ØµØ­ÙŠØ­Ø©
    all_bubbles[key] = [{"id": i + 1, "points": [[int(round(x)), int(round(y))] for x, y in b]} for i, b in enumerate(bubbles)]
    
    print(f"âœ… Processed {img_file}, found {len(bubbles)} clean bubbles.")

# ==========================
# ğŸ”¹ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\nğŸ‰ All unique bubbles saved to:\n{output_path}")


; ØŸØŸØŸØŸ Ø§ÙØ¶Ù„ ÙˆØ§Ø­Ø¯ Ø­ØªÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬##########################
##############
##############################

from ultralytics import YOLO
import os
import json
import cv2
import numpy as np
import math

# ==========================
# ğŸ”¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬
# ==========================
# ğŸš¨ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙƒØ«Ø± Ø¯Ù‚Ø© Ø§Ù„Ù…ÙØ´Ø§Ø± Ø¥Ù„ÙŠÙ‡ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø´Ø±ÙˆØ¹Ùƒ
MODEL_FILENAME = "comic-speech-bubble-detector.pt" # Ø£Ùˆ "yolov8m.pt"
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©
CONFIDENCE_THRESHOLD = 0.15  # ØªÙ… Ø®ÙØ¶Ù‡ Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ù„ÙˆÙ†Ø© ÙˆØ§Ù„ØºØ§Ù…Ù‚Ø©
SLICE_OVERLAP = 300          # ØªØ¯Ø§Ø®Ù„ Ø¬ÙŠØ¯ Ù„Ù„ØµÙˆØ± Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
SLICE_HEIGHT = 2500

try:
    model = YOLO(model_path)
    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {MODEL_FILENAME}")
except Exception as e:
    print(f"FATAL ERROR: Failed to load YOLO model from {model_path}. Error: {e}")
    exit()

# ==========================
# ğŸ”¹ Ø¯Ø§Ù„Ø© ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© (Ù…ÙØ­Ø³Ù‘Ù†Ø© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†)
# ==========================
def preprocess_image(img):
    """ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† ØªØ­Ø³ÙŠÙ†Ø§Øª HSV Ùˆ LAB Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø§Ù„Ù„ÙˆÙ†ÙŠ ÙˆØ§Ù„Ø³Ø·ÙˆØ¹."""
    # ØªØ­Ø³ÙŠÙ† HSV (Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ´Ø¨Ø¹)
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8)) # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø§Ù„Ù„ÙˆÙ†ÙŠ
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)
    
    # ØªØ­Ø³ÙŠÙ† LAB (Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ ÙˆØ§Ù„Ø­Ø¯ÙˆØ¯)
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    # Ø¯Ù…Ø¬ Ø§Ù„ØªØ­Ø³ÙŠÙ†ÙŠÙ† (60% LAB + 40% HSV)
    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# ğŸ”¹ Ø¯Ø§Ù„Ø© ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        
        # Ø¶Ø¨Ø· Ø§Ù„Ø´Ø±ÙŠØ­Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = h - slice_height
            if y_start < 0: y_start = 0
            y_end = h 
        
        slices.append((image[y_start:y_end, :].copy(), y_start))
        
        if y_end == h:
            break
            
        y_start += (slice_height - overlap)
        if y_start >= h:
             break
             
    return slices

# ==========================
# ğŸ”¹ IOU Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø§Ø®Ù„
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# ğŸ”¹ Ø¯Ø§Ù„Ø© Ø§Ù„Ø¯Ù…Ø¬ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙˆÙŠØ©
# ==========================
def merge_and_clean_boxes(boxes_raw, merge_iou_thresh=0.4): # Ø¹ØªØ¨Ø© Ø¯Ù…Ø¬ Ù…Ù†Ø®ÙØ¶Ø© Ù„Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ù‚Ø·ÙˆØ¹Ø©
    """
    ØªÙ‚ÙˆÙ… Ø¨Ø¯Ù…Ø¬ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ø§Ù„Ù…ØªØ¯Ø§Ø®Ù„Ø© Ø¨Ø´Ø¯Ø©ØŒ Ø«Ù… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©.
    """
    if not boxes_raw: return []
    
    boxes = np.array(boxes_raw, dtype=np.float32)
    merged_boxes = []
    processed = set() 

    # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø¹Ø¯ÙˆØ§Ù†ÙŠ (Aggressive Merging)
    for i in range(len(boxes)):
        if i in processed: continue
        
        current_box = boxes[i]
        overlaps_indices = [i] 
        
        for j in range(i + 1, len(boxes)):
            if j in processed: continue
            
            iou = box_iou(current_box, boxes[j])
            
            if iou > merge_iou_thresh: # Ø§Ù„Ø¯Ù…Ø¬ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ¯Ø§Ø®Ù„ 40% Ø£Ùˆ Ø£ÙƒØ«Ø±
                overlaps_indices.append(j)
        
        all_overlapping_boxes = boxes[overlaps_indices]
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªØ·ÙŠÙ„ Ù…Ø­ÙŠØ· ÙŠØºØ·ÙŠ ÙƒÙ„ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡
        x1_min = np.min(all_overlapping_boxes[:, 0])
        y1_min = np.min(all_overlapping_boxes[:, 1])
        x2_max = np.max(all_overlapping_boxes[:, 2])
        y2_max = np.max(all_overlapping_boxes[:, 3])
        
        merged_boxes.append((x1_min, y1_min, x2_max, y2_max))
        
        for idx in overlaps_indices:
            processed.add(idx)
            
    # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: ØªØ·Ø¨ÙŠÙ‚ NMS Ø®ÙÙŠÙ Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¹Ø§Ø±Ø¶
    final_clean_boxes = []
    if merged_boxes:
        merged_boxes_np = np.array(merged_boxes, dtype=np.float32)
        suppressed = np.zeros(len(merged_boxes_np), dtype=bool)
        
        for i in range(len(merged_boxes_np)):
            if suppressed[i]: continue
            
            final_clean_boxes.append(merged_boxes_np[i].tolist())
            
            for j in range(i + 1, len(merged_boxes_np)):
                if suppressed[j]: continue
                
                iou = box_iou(merged_boxes_np[i], merged_boxes_np[j])
                # Ø¹ØªØ¨Ø© IOU Ù…Ù†Ø®ÙØ¶Ø© Ø¬Ø¯Ø§Ù‹ (0.1) Ù„Ù„Ø­Ø°Ù
                if iou > 0.1: 
                    suppressed[j] = True

    return final_clean_boxes

# ==========================
# ğŸ”¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"Error: Image folder not found at '{image_folder}'")
    exit()
    
image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {img_path}")
        continue

    # 1. ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
    enhanced_img = preprocess_image(image)

    h, w, _ = image.shape
    boxes = [] # Ù‚Ø§Ø¦Ù…Ø© Ù„Ø­ÙØ¸ ÙƒÙ„ Ø§Ù„Ø§ÙƒØªØ´Ø§ÙØ§Øª

    # 2. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø©
    slices = slice_image(enhanced_img, overlap=SLICE_OVERLAP) if h > SLICE_HEIGHT else [(enhanced_img, 0)]
    
    for slice_img, offset_y in slices:
        # Ù†Ù…Ø±Ø± numpy array Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„
        results = model(slice_img, imgsz=1280, conf=CONFIDENCE_THRESHOLD, verbose=False) 
        
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.conf.cpu().numpy()):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    
                    x1, y1, x2, y2 = box.tolist()
                    
                    # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
                    x1, y1, x2, y2 = x1, y1 + offset_y, x2, y2 + offset_y
                    
                    if (x2 - x1) * (y2 - y1) < 2000: # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§
                        continue
                        
                    # Ù†Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø§ÙƒØªØ´Ø§ÙØ§Øª Ø¯ÙˆÙ† ØªØµÙÙŠØ©
                    boxes.append((x1, y1, x2, y2))
    
    # 3. ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø§Ù„Ø© Ø§Ù„Ø¯Ù…Ø¬ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
    clean_boxes = merge_and_clean_boxes(boxes, merge_iou_thresh=0.4) 

    bubbles = []
    for x1, y1, x2, y2 in clean_boxes:
        # Ù†Ø­ÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ·ÙŠÙ„ Ø§Ù„Ù…Ø­ÙŠØ· Ø¥Ù„Ù‰ Ù…Ø¶Ù„Ø¹ Ø±Ø¨Ø§Ø¹ÙŠ (Path)
        bubbles.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])

    key = f"{idx:02d}_mask"
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø¥Ù„Ù‰ Ø£Ø¹Ø¯Ø§Ø¯ ØµØ­ÙŠØ­Ø©
    all_bubbles[key] = [{"id": i + 1, "points": [[int(round(x)), int(round(y))] for x, y in b]} for i, b in enumerate(bubbles)]
    
    print(f"âœ… Processed {img_file}, found {len(bubbles)} clean bubbles.")

# ==========================
# ğŸ”¹ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\nğŸ‰ All unique bubbles saved to:\n{output_path}")

##############
; Ø§ÙØ¶Ù„ Ù…Ù† Ø§Ù„Ø³Ø§Ø¨Ù‚ 

from ultralytics import YOLO
import os
import json
import cv2
import numpy as np

# ==========================
# ğŸ”¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬
# ==========================
MODEL_FILENAME = "comic-speech-bubble-detector.pt"
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©
CONFIDENCE_THRESHOLD = 0.15
SLICE_OVERLAP = 300
SLICE_HEIGHT = 2500

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
try:
    model = YOLO(model_path)
    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {MODEL_FILENAME}")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† {model_path}: {e}")
    exit()

# ==========================
# ğŸ”¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
# ==========================
def preprocess_image(img):
    """
    ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ù„Ø²ÙŠØ§Ø¯Ø© ÙˆØ¶ÙˆØ­ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø­ØªÙ‰ Ø°Ø§Øª Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„ØºØ§Ù…Ù‚Ø© Ø£Ùˆ Ø§Ù„Ø´ÙØ§ÙØ©.
    """
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ HSV Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)

    # ØªØ­Ø³ÙŠÙ† LAB Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙÙŠ Ø§Ù„Ø­ÙˆØ§Ù Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ ÙˆØ§Ù„Ø®Ù„ÙÙŠØ§Øª Ø§Ù„ØºØ§Ù…Ù‚Ø©
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    # Ø¯Ù…Ø¬ LAB + HSV Ù„Ù†ØªÙŠØ¬Ø© Ø£ÙƒØ«Ø± ØªÙˆØ§Ø²Ù†Ø§Ù‹
    combined = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)

    # ØªØµØ­ÙŠØ­ Ø§Ù„Ø¬Ø§Ù…Ø§ (Gamma correction) Ù„ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„ØºØ§Ù…Ù‚Ø© ÙˆØ§Ù„Ø´ÙØ§ÙØ©
    gamma = 1.5  # ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ Ø¨ÙŠÙ† 1.3 Ùˆ 1.8 Ø­Ø³Ø¨ Ø§Ù„ØµÙˆØ±
    inv_gamma = 1.0 / gamma
    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in np.arange(256)]).astype("uint8")
    final = cv2.LUT(combined, table)

    return final

# ==========================
# ğŸ”¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = max(0, h - slice_height)
            y_end = h
        slices.append((image[y_start:y_end, :].copy(), y_start))
        if y_end == h:
            break
        y_start += (slice_height - overlap)
    return slices

# ==========================
# ğŸ”¹ IOU Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø§Ø®Ù„
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# ğŸ”¹ Ø¯Ù…Ø¬ ÙˆØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª
# ==========================
def merge_and_clean_boxes(boxes_raw, merge_iou_thresh=0.4):
    if not boxes_raw:
        return []
    boxes = np.array(boxes_raw, dtype=np.float32)
    merged_boxes, processed = [], set()

    for i in range(len(boxes)):
        if i in processed:
            continue
        current_box = boxes[i]
        overlaps_indices = [i]
        for j in range(i + 1, len(boxes)):
            if j in processed:
                continue
            if box_iou(current_box, boxes[j]) > merge_iou_thresh:
                overlaps_indices.append(j)
        all_overlapping_boxes = boxes[overlaps_indices]
        x1_min = np.min(all_overlapping_boxes[:, 0])
        y1_min = np.min(all_overlapping_boxes[:, 1])
        x2_max = np.max(all_overlapping_boxes[:, 2])
        y2_max = np.max(all_overlapping_boxes[:, 3])
        merged_boxes.append((x1_min, y1_min, x2_max, y2_max))
        for idx in overlaps_indices:
            processed.add(idx)

    # ØªÙ†Ø¸ÙŠÙ Ø¥Ø¶Ø§ÙÙŠ
    final_clean_boxes = []
    suppressed = np.zeros(len(merged_boxes), dtype=bool)
    for i in range(len(merged_boxes)):
        if suppressed[i]:
            continue
        final_clean_boxes.append(merged_boxes[i])
        for j in range(i + 1, len(merged_boxes)):
            if suppressed[j]:
                continue
            if box_iou(merged_boxes[i], merged_boxes[j]) > 0.1:
                suppressed[j] = True
    return final_clean_boxes

# ==========================
# ğŸ”¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ==========================
all_bubbles = {}
if not os.path.exists(image_folder):
    print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµÙˆØ±: {image_folder}")
    exit()

image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {img_path}")
        continue

    enhanced_img = preprocess_image(image)
    h, w, _ = image.shape
    boxes = []
    slices = slice_image(enhanced_img) if h > SLICE_HEIGHT else [(enhanced_img, 0)]

    for slice_img, offset_y in slices:
        results = model(slice_img, imgsz=1280, conf=CONFIDENCE_THRESHOLD, verbose=False)
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.conf.cpu().numpy()):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    x1, y1, x2, y2 = box.tolist()
                    y1 += offset_y
                    y2 += offset_y
                    if (x2 - x1) * (y2 - y1) < 1500:
                        continue
                    boxes.append((x1, y1, x2, y2))

    clean_boxes = merge_and_clean_boxes(boxes, merge_iou_thresh=0.4)
    bubbles = []
    for x1, y1, x2, y2 in clean_boxes:
        bubbles.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])

    key = f"{idx:02d}_mask"
    all_bubbles[key] = [{"id": i + 1, "points": [[int(x), int(y)] for x, y in b]} for i, b in enumerate(bubbles)]
    print(f"âœ… {img_file}: {len(bubbles)} ÙÙ‚Ø§Ø¹Ø© Ù…ÙƒØªØ´ÙØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ø³ÙŠÙ†.")

# ==========================
# ğŸ”¹ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\nğŸ‰ ØªÙ… Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª ÙÙŠ:\n{output_path}")

ØŸØŸØŸØŸ Ø¯Ù‚Ù‡ Ù…Ù…ØªØ§Ø²Ù‡3#####################
####################
######################












from ultralytics import YOLO
import easyocr
import os
import json
import cv2
import numpy as np
from shapely.geometry import Polygon

# ==========================
# ğŸ”¹ Setup Paths and Model
# ==========================
MODEL_FILENAME = "comic-speech-bubble-detector.pt"  # Specialized model for speech bubbles
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

# Sensitivity settings
CONFIDENCE_THRESHOLD = 0.15  # Lowered to detect colored and dark bubbles
SLICE_OVERLAP = 300          # Good overlap for long images
SLICE_HEIGHT = 2500

try:
    model = YOLO(model_path)
    print(f"âœ… Loaded model: {MODEL_FILENAME}")
except Exception as e:
    print(f"FATAL ERROR: Failed to load YOLO model from {model_path}. Error: {e}")
    exit()

# Load EasyOCR
try:
    ocr = easyocr.Reader(['en', 'ja'], gpu=True)  # Support English and Japanese
except Exception as e:
    print(f"âš ï¸ Falling back to CPU for EasyOCR: {e}")
    ocr = easyocr.Reader(['en', 'ja'], gpu=False)

# ==========================
# ğŸ”¹ Image Enhancement (Optimized for all colors and contrast)
# ==========================
def preprocess_image(img):
    """Combines HSV and LAB enhancements to increase color and brightness contrast."""
    # HSV enhancement (brightness and saturation)
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))  # Increase color contrast
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)
    
    # LAB enhancement (for white bubbles and edges)
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    # Combine enhancements (60% LAB + 40% HSV)
    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# ğŸ”¹ Slice Long Image
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = max(0, h - slice_height)
            y_end = h
        slices.append((image[y_start:y_end, :].copy(), y_start))
        if y_end == h:
            break
        y_start += (slice_height - overlap)
    return slices

# ==========================
# ğŸ”¹ IOU for Overlap Calculation
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# ğŸ”¹ Merge and Clean Boxes Strongly
# ==========================
def merge_and_clean_boxes(boxes_raw, merge_iou_thresh=0.4):  # Low merge threshold for sliced bubbles
    """
    Merges heavily overlapping detected parts, then cleans the final results.
    """
    if not boxes_raw: return []
    
    boxes = np.array(boxes_raw, dtype=np.float32)
    merged_boxes = []
    processed = set() 

    # Phase 1: Aggressive Merging
    for i in range(len(boxes)):
        if i in processed: continue
        
        current_box = boxes[i]
        overlaps_indices = [i] 
        
        for j in range(i + 1, len(boxes)):
            if j in processed: continue
            
            iou = box_iou(current_box, boxes[j])
            
            if iou > merge_iou_thresh:  # Merge if overlap is 40% or more
                overlaps_indices.append(j)
        
        all_overlapping_boxes = boxes[overlaps_indices]
        
        # Create bounding rectangle covering all parts
        x1_min = np.min(all_overlapping_boxes[:, 0])
        y1_min = np.min(all_overlapping_boxes[:, 1])
        x2_max = np.max(all_overlapping_boxes[:, 2])
        y2_max = np.max(all_overlapping_boxes[:, 3])
        
        merged_boxes.append((x1_min, y1_min, x2_max, y2_max))
        
        for idx in overlaps_indices:
            processed.add(idx)
            
    # Phase 2: Light NMS for incidental duplicate cleaning
    final_clean_boxes = []
    if merged_boxes:
        merged_boxes_np = np.array(merged_boxes, dtype=np.float32)
        suppressed = np.zeros(len(merged_boxes_np), dtype=bool)
        
        for i in range(len(merged_boxes_np)):
            if suppressed[i]: continue
            
            final_clean_boxes.append(merged_boxes_np[i].tolist())
            
            for j in range(i + 1, len(merged_boxes_np)):
                if suppressed[j]: continue
                
                iou = box_iou(merged_boxes_np[i], merged_boxes_np[j])
                # Very low IOU threshold (0.1) for deletion
                if iou > 0.1: 
                    suppressed[j] = True

    return final_clean_boxes

# ==========================
# ğŸ”¹ Main Processing
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"Error: Image folder not found at '{image_folder}'")
    exit()
    
image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ Failed to read image: {img_path}")
        continue

    # 1. Preprocess image
    enhanced_img = preprocess_image(image)

    h, w, _ = image.shape
    boxes = [] # List to store all detections

    # 2. Slice image
    slices = slice_image(enhanced_img, overlap=SLICE_OVERLAP) if h > SLICE_HEIGHT else [(enhanced_img, 0)]
    
    for slice_img, offset_y in slices:
        # Pass numpy array directly to model
        results = model(slice_img, imgsz=1280, conf=CONFIDENCE_THRESHOLD, verbose=False) 
        
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.conf.cpu().numpy()):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    
                    x1, y1, x2, y2 = box.tolist()
                    
                    # Adjust coordinates relative to original image
                    x1, y1, x2, y2 = x1, y1 + offset_y, x2, y2 + offset_y
                    
                    if (x2 - x1) * (y2 - y1) < 2000: # Ignore very small bubbles
                        continue
                        
                    # Collect all detections without filtering
                    boxes.append((x1, y1, x2, y2))
    
    # 3. Apply merge and clean function once
    clean_boxes = merge_and_clean_boxes(boxes, merge_iou_thresh=0.4) 

    bubbles = []
    for x1, y1, x2, y2 in clean_boxes:
        # Convert bounding rectangle to quadrilateral (Path)
        bubbles.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])

    key = f"{idx:02d}_mask"
    # Convert coordinates to integers
    all_bubbles[key] = [{"id": i + 1, "points": [[int(round(x)), int(round(y))] for x, y in b]} for i, b in enumerate(bubbles)]
    
    print(f"âœ… Processed {img_file}, found {len(bubbles)} clean bubbles.")

# ==========================
# ğŸ”¹ Save Results to JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\nğŸ‰ All unique bubbles saved to:\n{output_path}")  


################ÙƒÙˆØ¯ Ù†Ø§Ø¬ ØªÙ„Ø§Ù„ØªÙ‡ Ù‚Ø¯Ø± ÙŠØ´ÙˆÙ Ø§Ù„ÙÙ‚Ø§Ø¹Ù‡ Ø§Ù„ØµØ±Ø§Ø®




from ultralytics import YOLO
import easyocr
import os
import json
import cv2
import numpy as np
import re

# ==========================
# ğŸ”¹ Setup Paths and Model
# ==========================
MODEL_FILENAME = "comic-speech-bubble-detector.pt"
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

CONFIDENCE_THRESHOLD = 0.05  # Lowered for more sensitive detection
SLICE_OVERLAP = 300
SLICE_HEIGHT = 2500

try:
    model = YOLO(model_path)
    print(f"âœ… Loaded model: {MODEL_FILENAME}")
except Exception as e:
    print(f"FATAL ERROR: Failed to load YOLO model from {model_path}. Error: {e}")
    exit()

try:
    reader = easyocr.Reader(['en','ja','ko'], gpu=True)
except Exception as e:
    print(f"âš ï¸ EasyOCR GPU failed, fallback CPU: {e}")
    reader = easyocr.Reader(['en','ja','ko'], gpu=False)

# ==========================
# ğŸ”¹ Image Preprocessing
# ==========================
def preprocess_image(img):
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)

    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# ğŸ”¹ Slice Image
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = max(0, h - slice_height)
            y_end = h
        slices.append((image[y_start:y_end, :].copy(), y_start))
        if y_end == h:
            break
        y_start += (slice_height - overlap)
    return slices

# ==========================
# ğŸ”¹ IOU Function
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# ğŸ”¹ Merge and Clean Boxes
# ==========================
def merge_and_clean_boxes(boxes_raw, merge_iou_thresh=0.4):
    if not boxes_raw: return []
    boxes = np.array(boxes_raw, dtype=np.float32)
    merged_boxes = []
    processed = set()
    for i in range(len(boxes)):
        if i in processed: continue
        current_box = boxes[i]
        overlaps_indices = [i]
        for j in range(i + 1, len(boxes)):
            if j in processed: continue
            if box_iou(current_box, boxes[j]) > merge_iou_thresh:
                overlaps_indices.append(j)
        all_boxes = boxes[overlaps_indices]
        x1_min = np.min(all_boxes[:,0])
        y1_min = np.min(all_boxes[:,1])
        x2_max = np.max(all_boxes[:,2])
        y2_max = np.max(all_boxes[:,3])
        merged_boxes.append((x1_min, y1_min, x2_max, y2_max))
        for idx in overlaps_indices: processed.add(idx)
    # Light NMS
    final_clean_boxes = []
    merged_boxes_np = np.array(merged_boxes, dtype=np.float32)
    suppressed = np.zeros(len(merged_boxes_np), dtype=bool)
    for i in range(len(merged_boxes_np)):
        if suppressed[i]: continue
        final_clean_boxes.append(merged_boxes_np[i].tolist())
        for j in range(i+1,len(merged_boxes_np)):
            if suppressed[j]: continue
            if box_iou(merged_boxes_np[i], merged_boxes_np[j]) > 0.1:
                suppressed[j] = True
    return final_clean_boxes

# ==========================
# ğŸ”¹ OCR / Text Verification
# ==========================
def has_meaningful_text(image, box, reader):
    x1, y1, x2, y2 = map(int, box)
    x1, y1 = max(0, x1-5), max(0, y1-5)
    x2, y2 = min(image.shape[1], x2+5), min(image.shape[0], y2+5)
    if x2<=x1 or y2<=y1: return True  # Always allow
    
    crop = image[y1:y2, x1:x2]
    if crop.size == 0: return True

    gray_crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    clahe_crop = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4,4))
    processed_crop = clahe_crop.apply(gray_crop)

    try:
        results = reader.readtext(processed_crop, detail=0)
    except:
        results = []

    # Always allow empty or faint bubbles
    if not results: return True
    for text in results:
        cleaned = re.sub(r'\s+','',text)
        if len(cleaned) > 1: return True
        if re.search(r'(\.{2,}|!+|\?+)', cleaned): return True
    return True

# ==========================
# ğŸ”¹ Main Processing
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"Error: Image folder not found at '{image_folder}'")
    exit()

image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg",".png",".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ Failed to read image: {img_path}")
        continue

    enhanced_img = preprocess_image(image)
    h, w, _ = image.shape
    boxes = []

    slices = slice_image(enhanced_img) if h>SLICE_HEIGHT else [(enhanced_img,0)]
    for slice_img, offset_y in slices:
        results = model(slice_img, imgsz=1280, conf=CONFIDENCE_THRESHOLD, verbose=False)
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.conf.cpu().numpy()):
                    if score < CONFIDENCE_THRESHOLD: continue
                    x1,y1,x2,y2 = box.tolist()
                    y1 += offset_y
                    y2 += offset_y
                    if (x2-x1)*(y2-y1) < 2000: continue
                    boxes.append((x1,y1,x2,y2))

    clean_boxes = merge_and_clean_boxes(boxes, merge_iou_thresh=0.4)
    bubbles = []
    for x1,y1,x2,y2 in clean_boxes:
        if has_meaningful_text(image, (x1,y1,x2,y2), reader):
            bubbles.append([[x1,y1],[x2,y1],[x2,y2],[x1,y2]])

    key = f"{idx:02d}_mask"
    all_bubbles[key] = [{"id":i+1, "points":[[int(round(x)),int(round(y))] for x,y in b]} for i,b in enumerate(bubbles)]
    print(f"âœ… Processed {img_file}, found {len(bubbles)} bubbles.")

# ==========================
# ğŸ”¹ Save JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path,"w",encoding="utf-8") as f:
    json.dump(all_bubbles,f,indent=2)

print(f"\nğŸ‰ All bubbles saved to: {output_path}")

@#############ØªÙ… Ø§ÙƒØªØ´ÙØ§ Ø§Ù„ÙÙ‚Ø§Ø¹Ù‡ Ø§Ù„ØªÙŠ Ù„ÙˆÙ†Ù‡Ø§ Ø§Ø²Ø±Ù‚ Ø§Ù„ÙƒÙˆØ¯ Ø±Ù‚Ù… 4














Ø§Ù„ÙƒÙˆØ¯ ÙƒÙˆÙŠØ³ Ø¬Ø¯Ø§
Ø¨Ø³ ÙÙŠ Ø¨Ø§Ø«Ø§Øª Ù…Ø¹Ù…ÙˆÙ„Ù‡ Ù…Ø±ØªÙŠÙ†
Ø­Ø§ÙˆÙ„ ØªØ­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ù‡ Ø¯ÙŠ Ø¨Ø­ÙŠØ« ÙƒÙ„ Ù†Øµ Ø¹Ù„ÙŠÙ‡ Ø¨Ø§Ø« ÙˆØ§Ø­Ø¯ Ø¨Ø³ Ø­ÙˆØ§Ù„ÙŠÙ† Ø§Ù„ÙÙ‚Ø§Ø¹Ù‡ Ø§Ù„Ø¨Ø§Ø« Ø§Ù„ÙƒØ¨ÙŠØ± ÙŠØ¹Ù†ÙŠ
Ø¨Ø³ Ø¹Ø§Ù…ØªØ§ Ø§Ù„ÙƒÙˆØ¯ Ø¬Ù…ÙŠÙŠÙ„ Ø¬Ø¯Ø§ ÙˆÙÙŠÙ‡ ÙƒÙ„ Ø§Ù„Ù„ÙŠ Ø§Ù†Ø§ Ø¹Ø§ÙŠØ²Ù‡ ÙˆØ¨ÙŠÙƒØªØ´Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø¨Ø§Ø¹Ù„ÙŠ Ù…Ø³ØªÙˆÙŠ
from ultralytics import YOLO
import os
import json
import cv2
import numpy as np
import re
from PIL import Image

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ MangaOCRØŒ ÙˆØ¥Ù„Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… EasyOCR
try:
    from manga_ocr import MangaOcr
    USE_MANGA_OCR = True
    print("âœ… Using MangaOCR for text validation (specialized for manga).")
except ImportError:
    import easyocr
    USE_MANGA_OCR = False
    print("âš ï¸ MangaOCR not found, falling back to EasyOCR. Install with: pip install manga-ocr")

# ==========================
# ğŸ”¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬
# ==========================
MODEL_FILENAME = "comic-speech-bubble-detector.pt"  # ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… yolov8m-seg.pt Ù„Ù€ segmentation
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©
CONFIDENCE_THRESHOLD = 0.05  # Ù…Ù†Ø®ÙØ¶Ø© Ù„ÙƒØ´Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ø²Ø±Ù‚Ø§Ø¡/Ø§Ù„ØµØ¹Ø¨Ø©
IOU_THRESHOLD = 0.5  # Ø¹ØªØ¨Ø© NMS Ù‚ÙŠØ§Ø³ÙŠØ©
SLICE_OVERLAP = 300
SLICE_HEIGHT = 2500
MIN_BUBBLE_AREA = 2000  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
try:
    model = YOLO(model_path)
    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {MODEL_FILENAME}")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
    exit()

# ØªØ­Ù…ÙŠÙ„ OCR
if USE_MANGA_OCR:
    try:
        ocr = MangaOcr()
    except Exception as e:
        print(f"âš ï¸ Failed to load MangaOCR: {e}. Falling back to EasyOCR.")
        USE_MANGA_OCR = False
        ocr = easyocr.Reader(['en', 'ja', 'ko'], gpu=True)
else:
    try:
        ocr = easyocr.Reader(['en', 'ja', 'ko'], gpu=True)
    except Exception as e:
        print(f"âš ï¸ EasyOCR GPU failed, using CPU: {e}")
        ocr = easyocr.Reader(['en', 'ja', 'ko'], gpu=False)

# ==========================
# ğŸ”¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
# ==========================
def preprocess_image(img):
    """ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ù„Ø²ÙŠØ§Ø¯Ø© ÙˆØ¶ÙˆØ­ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª."""
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)

    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# ğŸ”¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    """ØªÙ‚Ø³Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¥Ù„Ù‰ Ø´Ø±Ø§Ø¦Ø­ Ù…Ø¹ ØªØ¯Ø§Ø®Ù„."""
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = max(0, h - slice_height)
            y_end = h
        slices.append((image[y_start:y_end, :].copy(), y_start))
        if y_end == h:
            break
        y_start += (slice_height - overlap)
    return slices

# ==========================
# ğŸ”¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠ Ø¨Ù€ OCR
# ==========================
def has_meaningful_text(image, box, ocr):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙÙ‚Ø§Ø¹Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†Øµ Ù…Ø¹Ù†ÙˆÙŠ."""
    x1, y1, x2, y2 = map(int, box)
    x1, y1 = max(0, x1-5), max(0, y1-5)
    x2, y2 = min(image.shape[1], x2+5), min(image.shape[0], y2+5)
    if x2 <= x1 or y2 <= y1:
        return False

    crop = image[y1:y2, x1:x2]
    if crop.size == 0:
        return False

    # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ù‚Ø·Ø¹ Ù„Ù€ OCR
    gray_crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    clahe_crop = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4,4))
    processed_crop = clahe_crop.apply(gray_crop)

    try:
        if USE_MANGA_OCR:
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ PIL.Image Ù„Ù€ MangaOCR
            pil_image = Image.fromarray(processed_crop)
            text = ocr(pil_image)
        else:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… EasyOCR
            results = ocr.readtext(processed_crop, detail=0)
            text = ' '.join(results) if results else ''
    except Exception as e:
        print(f"âš ï¸ OCR failed for box [{x1}, {y1}, {x2}, {y2}]: {e}")
        return False

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠ
    cleaned = re.sub(r'\s+', '', text) if text else ''
    if len(cleaned) > 1 or re.search(r'(\.{2,}|!+|\?+)', cleaned):
        return True
    return False

# ==========================
# ğŸ”¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµÙˆØ±: {image_folder}")
    exit()

image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {img_path}")
        continue

    # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
    enhanced_img = preprocess_image(image)
    h, w, _ = image.shape
    all_boxes = []

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø·ÙˆÙŠÙ„Ø©
    slices = slice_image(enhanced_img) if h > SLICE_HEIGHT else [(enhanced_img, 0)]
    for slice_img, offset_y in slices:
        # ÙƒØ´Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… YOLO
        results = model(slice_img, imgsz=640, conf=CONFIDENCE_THRESHOLD, iou=IOU_THRESHOLD, verbose=False)
        for r in results:
            if r.boxes:
                boxes = r.boxes.xyxy.cpu().numpy()
                scores = r.boxes.conf.cpu().numpy()
                for box, score in zip(boxes, scores):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    x1, y1, x2, y2 = box.tolist()
                    y1 += offset_y
                    y2 += offset_y
                    area = (x2 - x1) * (y2 - y1)
                    if area < MIN_BUBBLE_AREA:
                        continue
                    all_boxes.append([x1, y1, x2, y2])

    # ØªØµÙÙŠØ© Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR
    valid_bubbles = []
    for box in all_boxes:
        if has_meaningful_text(image, box, ocr):
            valid_bubbles.append([[box[0], box[1]], [box[2], box[1]], [box[2], box[3]], [box[0], box[3]]])

    # Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØªØ§Ø­ Ù„Ù„Ù€ JSON
    key = f"{idx:02d}_mask"
    all_bubbles[key] = [{"id": i + 1, "points": [[int(round(x)), int(round(y))] for x, y in b]} for i, b in enumerate(valid_bubbles)]
    print(f"âœ… Processed {img_file}, found {len(valid_bubbles)} valid bubbles.")

# ==========================
# ğŸ”¹ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\nğŸ‰ All unique bubbles saved to:\n{output_path}")


|||Ø§ÙƒØ«Ø± Ø¯Ù‚Ù‡ Ø¨Ø³ Ø¨Ø§Ø«Ø§Øª ÙƒØªÙŠØ±




from ultralytics import YOLO
import os
import json
import cv2
import numpy as np
import re
from PIL import Image

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ MangaOCRØŒ ÙˆØ¥Ù„Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… EasyOCR
try:
    from manga_ocr import MangaOcr
    USE_MANGA_OCR = True
    print("âœ… Using MangaOCR for text validation (specialized for manga).")
except ImportError:
    import easyocr
    USE_MANGA_OCR = False
    print("âš ï¸ MangaOCR not found, falling back to EasyOCR. Install with: pip install manga-ocr")

# ==========================
# ğŸ”¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬
# ==========================
MODEL_FILENAME = "comic-speech-bubble-detector.pt"  # ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… yolov8m-seg.pt Ù„Ù€ segmentation
model_path = os.path.join("model", MODEL_FILENAME)
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©
CONFIDENCE_THRESHOLD = 0.05  # Ù…Ù†Ø®ÙØ¶Ø© Ù„ÙƒØ´Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ø²Ø±Ù‚Ø§Ø¡/Ø§Ù„ØµØ¹Ø¨Ø©
IOU_THRESHOLD = 0.5  # Ø¹ØªØ¨Ø© NMS Ù‚ÙŠØ§Ø³ÙŠØ©
SLICE_OVERLAP = 300
SLICE_HEIGHT = 2500
MIN_BUBBLE_AREA = 2000  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
try:
    model = YOLO(model_path)
    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {MODEL_FILENAME}")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
    exit()

# ØªØ­Ù…ÙŠÙ„ OCR
if USE_MANGA_OCR:
    try:
        ocr = MangaOcr()
    except Exception as e:
        print(f"âš ï¸ Failed to load MangaOCR: {e}. Falling back to EasyOCR.")
        USE_MANGA_OCR = False
        ocr = easyocr.Reader(['en', 'ja', 'ko'], gpu=True)
else:
    try:
        ocr = easyocr.Reader(['en', 'ja', 'ko'], gpu=True)
    except Exception as e:
        print(f"âš ï¸ EasyOCR GPU failed, using CPU: {e}")
        ocr = easyocr.Reader(['en', 'ja', 'ko'], gpu=False)

# ==========================
# ğŸ”¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
# ==========================
def preprocess_image(img):
    """ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ù„Ø²ÙŠØ§Ø¯Ø© ÙˆØ¶ÙˆØ­ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª."""
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    clahe_s = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
    s = clahe_s.apply(s)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced_hsv = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)

    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe_l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe_l.apply(l)
    lab_enhanced = cv2.merge([l, a, b])
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    final = cv2.addWeighted(enhanced_lab, 0.6, enhanced_hsv, 0.4, 0)
    return final

# ==========================
# ğŸ”¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
# ==========================
def slice_image(image, slice_height=SLICE_HEIGHT, overlap=SLICE_OVERLAP):
    """ØªÙ‚Ø³Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¥Ù„Ù‰ Ø´Ø±Ø§Ø¦Ø­ Ù…Ø¹ ØªØ¯Ø§Ø®Ù„."""
    h, w = image.shape[:2]
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_height, h)
        if y_end == h and y_start < h - slice_height + overlap:
            y_start = max(0, h - slice_height)
            y_end = h
        slices.append((image[y_start:y_end, :].copy(), y_start))
        if y_end == h:
            break
        y_start += (slice_height - overlap)
    return slices

# ==========================
# ğŸ”¹ IOU Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¯Ø§Ø®Ù„
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# ğŸ”¹ Ø¯Ù…Ø¬ ÙˆØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª (Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±)
# ==========================
def merge_and_clean_boxes(boxes_raw, scores_raw, merge_iou_thresh=0.5):
    if not boxes_raw:
        return [], []
    boxes = np.array(boxes_raw, dtype=np.float32)
    scores = np.array(scores_raw, dtype=np.float32)
    merged_boxes = []
    merged_scores = []
    processed = set()

    for i in range(len(boxes)):
        if i in processed:
            continue
        current_box = boxes[i]
        current_score = scores[i]
        overlaps_indices = [i]
        for j in range(i + 1, len(boxes)):
            if j in processed:
                continue
            if box_iou(current_box, boxes[j]) > merge_iou_thresh:
                overlaps_indices.append(j)
        all_overlapping_boxes = boxes[overlaps_indices]
        x1_min = np.min(all_overlapping_boxes[:, 0])
        y1_min = np.min(all_overlapping_boxes[:, 1])
        x2_max = np.max(all_overlapping_boxes[:, 2])
        y2_max = np.max(all_overlapping_boxes[:, 3])
        merged_boxes.append([x1_min, y1_min, x2_max, y2_max])
        merged_scores.append(np.max(scores[overlaps_indices]))  # Ø§Ø®ØªÙŠØ§Ø± Ø£Ø¹Ù„Ù‰ score
        for idx in overlaps_indices:
            processed.add(idx)

    # ØªÙ†Ø¸ÙŠÙ Ø¥Ø¶Ø§ÙÙŠ Ø¨Ù€ NMS Ø®ÙÙŠÙ
    final_boxes = []
    final_scores = []
    suppressed = np.zeros(len(merged_boxes), dtype=bool)
    for i in range(len(merged_boxes)):
        if suppressed[i]:
            continue
        final_boxes.append(merged_boxes[i])
        final_scores.append(merged_scores[i])
        for j in range(i + 1, len(merged_boxes)):
            if suppressed[j]:
                continue
            if box_iou(merged_boxes[i], merged_boxes[j]) > 0.3:  # Ø¹ØªØ¨Ø© Ø£Ù‚Ù„ Ù„Ù„ØªÙ†Ø¸ÙŠÙ
                suppressed[j] = True
    return final_boxes, final_scores

# ==========================
# ğŸ”¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠ Ø¨Ù€ OCR
# ==========================
def has_meaningful_text(image, box, ocr):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙÙ‚Ø§Ø¹Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†Øµ Ù…Ø¹Ù†ÙˆÙŠ."""
    x1, y1, x2, y2 = map(int, box)
    x1, y1 = max(0, x1-5), max(0, y1-5)
    x2, y2 = min(image.shape[1], x2+5), min(image.shape[0], y2+5)
    if x2 <= x1 or y2 <= y1:
        return False

    crop = image[y1:y2, x1:x2]
    if crop.size == 0:
        return False

    # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ù‚Ø·Ø¹ Ù„Ù€ OCR
    gray_crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    clahe_crop = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4,4))
    processed_crop = clahe_crop.apply(gray_crop)

    try:
        if USE_MANGA_OCR:
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ PIL.Image Ù„Ù€ MangaOCR
            pil_image = Image.fromarray(processed_crop)
            text = ocr(pil_image)
        else:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… EasyOCR
            results = ocr.readtext(processed_crop, detail=0)
            text = ' '.join(results) if results else ''
    except Exception as e:
        print(f"âš ï¸ OCR failed for box [{x1}, {y1}, {x2}, {y2}]: {e}")
        return False

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠ
    cleaned = re.sub(r'\s+', '', text) if text else ''
    if len(cleaned) > 1 or re.search(r'(\.{2,}|!+|\?+)', cleaned):
        return True
    return False

# ==========================
# ğŸ”¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ==========================
all_bubbles = {}

if not os.path.exists(image_folder):
    print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµÙˆØ±: {image_folder}")
    exit()

image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {img_path}")
        continue

    # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
    enhanced_img = preprocess_image(image)
    h, w, _ = image.shape
    all_boxes = []
    all_scores = []

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø·ÙˆÙŠÙ„Ø©
    slices = slice_image(enhanced_img) if h > SLICE_HEIGHT else [(enhanced_img, 0)]
    for slice_img, offset_y in slices:
        # ÙƒØ´Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… YOLO
        results = model(slice_img, imgsz=640, conf=CONFIDENCE_THRESHOLD, iou=IOU_THRESHOLD, verbose=False)
        for r in results:
            if r.boxes:
                boxes = r.boxes.xyxy.cpu().numpy()
                scores = r.boxes.conf.cpu().numpy()
                for box, score in zip(boxes, scores):
                    if score < CONFIDENCE_THRESHOLD:
                        continue
                    x1, y1, x2, y2 = box.tolist()
                    y1 += offset_y
                    y2 += offset_y
                    area = (x2 - x1) * (y2 - y1)
                    if area < MIN_BUBBLE_AREA:
                        continue
                    all_boxes.append([x1, y1, x2, y2])
                    all_scores.append(score)

    # Ø¯Ù…Ø¬ ÙˆØªÙ†Ø¸ÙŠÙ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±
    clean_boxes, clean_scores = merge_and_clean_boxes(all_boxes, all_scores, merge_iou_thresh=IOU_THRESHOLD)

    # ØªØµÙÙŠØ© Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR
    valid_bubbles = []
    for box in clean_boxes:
        if has_meaningful_text(image, box, ocr):
            valid_bubbles.append([[box[0], box[1]], [box[2], box[1]], [box[2], box[3]], [box[0], box[3]]])

    # Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØªØ§Ø­ Ù„Ù„Ù€ JSON
    key = f"{idx:02d}_mask"
    all_bubbles[key] = [{"id": i + 1, "points": [[int(round(x)), int(round(y))] for x, y in b]} for i, b in enumerate(valid_bubbles)]
    print(f"âœ… Processed {img_file}, found {len(valid_bubbles)} valid bubbles.")

# ==========================
# ğŸ”¹ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\nğŸ‰ All unique bubbles saved to:\n{output_path}")

 Ø¨Ø§Ø«Ø§ÙƒØª ÙƒØ«ÙŠØ± Ù†ÙØ³ Ø§Ù„ÙƒÙ„Ø§Ù… 




















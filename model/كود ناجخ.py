from ultralytics import YOLO
import os
import json
import cv2
import numpy as np
import easyocr

# ğŸ”¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
model_path = "model/yolov8m.pt"  # Ø§Ø³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ Ù…Ø­Ø³Ù†Ù‹Ø§ Ù…Ù† https://huggingface.co/ogkalu/comic-speech-bubble-detector-yolov8m
image_folder = "images"
output_path = "C:/Users/abdoh/Downloads/01/cleaned/all_bubbles.json"

# ğŸ”¹ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ YOLO
model = YOLO(model_path)

# ğŸ”¹ ØªØ­Ù…ÙŠÙ„ EasyOCR Ù„ØªØªØ¨Ø¹ Ø§Ù„Ù†ØµÙˆØµ
reader = easyocr.Reader(['en', 'ja'], gpu=True)  # Ø¯Ø¹Ù… Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙˆØ§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ©

# ==========================
# ğŸ”¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„Ø¥Ø¨Ø±Ø§Ø² Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ù„ÙˆÙ†Ø©
# ==========================
def preprocess_image(img):
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ HSV ÙˆØ²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ´Ø¨Ø¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    s = cv2.add(s, 50)  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ´Ø¨Ø¹ Ù„Ø¥Ø¨Ø±Ø§Ø² Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ù„ÙˆÙ†Ø©
    s = np.clip(s, 0, 255)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    v = clahe.apply(v)
    hsv_enhanced = cv2.merge([h, s, v])
    enhanced = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)

    # ğŸ”¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… adaptive thresholding
    gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)
    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
    enhanced = cv2.addWeighted(enhanced, 0.8, cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR), 0.2, 0)
    return enhanced

# ==========================
# ğŸ”¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù†ØµÙˆØµ Ø¯Ø§Ø®Ù„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø©
# ==========================
def has_text(image, box):
    x1, y1, x2, y2 = map(int, box)
    x1, y1 = max(0, x1), max(0, y1)
    x2, y2 = min(image.shape[1], x2), min(image.shape[0], y2)
    if x2 <= x1 or y2 <= y1:
        return False
    crop = image[y1:y2, x1:x2]
    if crop.size == 0:
        return False
    results = reader.readtext(crop, detail=0)  # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØµÙˆØµ ÙÙ‚Ø·
    return len(results) > 0  # Ø¥Ø±Ø¬Ø§Ø¹ True Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ Ù†Øµ

# ==========================
# ğŸ”¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
# ==========================
def slice_image(image, slice_height=2500, overlap=300):
    h, w = image.shape[:2]
    slices = []
    start_y = 0
    while start_y < h:
        end_y = min(start_y + slice_height, h)
        slices.append((image[start_y:end_y, :].copy(), start_y))
        if end_y >= h:
            break
        start_y = end_y - overlap
    return slices

# ==========================
# ğŸ”¹ IOU Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# ğŸ”¹ Ø¯Ø§Ù„Ø© Ø­Ø°Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
# ==========================
def remove_duplicates(boxes, iou_thresh=0.7, dist_thresh=100):
    unique = []
    for box in boxes:
        duplicate = False
        x1, y1, x2, y2 = box
        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
        for ux1, uy1, ux2, uy2 in unique:
            ucx, ucy = (ux1 + ux2) / 2, (uy1 + uy2) / 2
            iou = box_iou(box, (ux1, uy1, ux2, uy2))
            dist = np.hypot(cx - ucx, cy - ucy)
            if iou > iou_thresh or dist < dist_thresh:
                duplicate = True
                break
        if not duplicate:
            unique.append(box)
    return unique

# ==========================
# ğŸ”¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ==========================
all_bubbles = {}
image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {img_path}")
        continue

    image = preprocess_image(image)
    h, w, _ = image.shape
    bubbles = []
    boxes = []

    # ØªÙ‚Ø³ÙŠÙ… Ù„Ùˆ Ø§Ù„ØµÙˆØ±Ø© Ø·ÙˆÙŠÙ„Ø©
    slices = slice_image(image) if h > 4000 else [(image, 0)]

    for slice_img, offset_y in slices:
        results = model(slice_img, imgsz=1280, conf=0.05)  # Ø®ÙØ¶ conf Ù„ÙƒØ´Ù Ø§Ù„Ù…Ø²ÙŠØ¯
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy, r.boxes.conf):
                    if score < 0.05:
                        continue
                    x1, y1, x2, y2 = box.tolist()
                    x1, y1, x2, y2 = x1, y1 + offset_y, x2, y2 + offset_y
                    if (x2 - x1) * (y2 - y1) < 2000:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø©
                        continue
                    # ğŸ”¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù†ØµÙˆØµ Ø¯Ø§Ø®Ù„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø©
                    if has_text(image, (x1, y1, x2, y2)):
                        boxes.append((x1, y1, x2, y2))

    # ğŸ§© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
    boxes = remove_duplicates(boxes)

    for x1, y1, x2, y2 in boxes:
        bubbles.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])

    key = f"{idx:02d}_mask"
    all_bubbles[key] = [{"id": i + 1, "points": [[int(x), int(y)] for x, y in b]} for i, b in enumerate(bubbles)]
    print(f"âœ… Processed {img_file}, found {len(bubbles)} text-containing bubbles.")

# ==========================
# ğŸ”¹ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\nğŸ‰ All text-containing bubbles saved to:\n{output_path}")


# Ø¨ÙŠØ§Ù†Ø§Øª Ø²ÙŠØ§Ø¯Ù‡ 




#######################


###################

from ultralytics import YOLO
import os
import json
import cv2
import numpy as np

model_path = "model/model.pt"
image_folder = "images"
output_path = r"C:\Users\abdoh\Downloads\01\cleaned\all_bubbles.json"

model = YOLO(model_path)

# ==========================
# ğŸ”¹ ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© (Ù„Ù„Ø®Ù„ÙÙŠØ§Øª Ø§Ù„ØºØ§Ù…Ù‚Ø© ÙˆØ§Ù„Ù…Ù„ÙˆÙ†Ø©)
# ==========================
def preprocess_image(img):
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ HSV Ùˆ LAB
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙÙŠ Ù‚Ù†Ø§Ø© Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© (V Ùˆ L)
    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
    hsv[:, :, 2] = clahe.apply(hsv[:, :, 2])
    lab[:, :, 0] = clahe.apply(lab[:, :, 0])

    # Ø¯Ù…Ø¬ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø«Ù„Ø§Ø«Ø© ÙÙŠ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ù„ØªÙ‚ÙˆÙŠØ© Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª
    hsv_bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    lab_bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    enhanced = cv2.addWeighted(hsv_bgr, 0.4, lab_bgr, 0.4, 0)
    enhanced = cv2.addWeighted(enhanced, 0.8, cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), 0.2, 0)

    # ØªØ¬Ø±Ø¨Ø© threshold Ø¨Ø³ÙŠØ· Ù„Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø¯Ø§ÙƒÙ†Ø© Ø¬Ø¯Ù‹Ø§ (ÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„ØºØ§Ù…Ù‚Ø©)
    dark_mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                      cv2.THRESH_BINARY_INV, 31, 5)
    dark_mask = cv2.cvtColor(dark_mask, cv2.COLOR_GRAY2BGR)
    enhanced = cv2.addWeighted(enhanced, 0.85, dark_mask, 0.15, 0)

    return enhanced

# ==========================
# ğŸ”¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
# ==========================
def slice_image(image, slice_height=2500, overlap=150):
    h, w = image.shape[:2]
    slices = []
    start_y = 0
    while start_y < h:
        end_y = min(start_y + slice_height, h)
        slices.append((image[start_y:end_y, :].copy(), start_y))
        if end_y >= h:
            break
        start_y = end_y - overlap
    return slices

# ==========================
# ğŸ”¹ IOU Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# ğŸ”¹ Ø¯Ø§Ù„Ø© Ø­Ø°Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
# ==========================
def remove_duplicates(boxes, iou_thresh=0.6, dist_thresh=50):
    unique = []
    for box in boxes:
        duplicate = False
        x1, y1, x2, y2 = box
        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
        for ux1, uy1, ux2, uy2 in unique:
            ucx, ucy = (ux1 + ux2) / 2, (uy1 + uy2) / 2
            iou = box_iou(box, (ux1, uy1, ux2, uy2))
            dist = np.hypot(cx - ucx, cy - ucy)
            if iou > iou_thresh or dist < dist_thresh:
                duplicate = True
                break
        if not duplicate:
            unique.append(box)
    return unique

# ==========================
# ğŸ”¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ==========================
all_bubbles = {}
image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {img_path}")
        continue

    image = preprocess_image(image)
    h, w, _ = image.shape
    bubbles = []
    boxes = []

    slices = slice_image(image) if h > 4000 else [(image, 0)]

    for slice_img, offset_y in slices:
        results = model(slice_img, imgsz=1280, conf=0.25)
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy, r.boxes.conf):
                    if score < 0.25:
                        continue
                    x1, y1, x2, y2 = box.tolist()
                    x1, y1, x2, y2 = x1, y1 + offset_y, x2, y2 + offset_y
                    if (x2 - x1) * (y2 - y1) < 2000:
                        continue
                    boxes.append((x1, y1, x2, y2))

    boxes = remove_duplicates(boxes)

    for x1, y1, x2, y2 in boxes:
        bubbles.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])

    key = f"{idx:02d}_mask"
    all_bubbles[key] = [{
        "id": i + 1,
        "points": [[int(x), int(y)] for x, y in b]
    } for i, b in enumerate(bubbles)]

    print(f"âœ… Processed {img_file}, found {len(bubbles)} bubbles.")

# ==========================
# ğŸ”¹ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\nğŸ‰ All unique bubbles saved to:\n{output_path}")


# Ø­Ù„Øª Ù…Ø´ÙƒÙ„Ù‡ Ø§Ù„ØªØ¯Ø§Ø®Ù„ ÙˆØ§ÙƒØªØ´ØªÙØª Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ØµØºÙŠØ±Ù‡ Ø§Ù„ØªÙŠ Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„ÙÙ‚Ø§Ø¹Ù‡ ÙˆØ§ÙƒØªØ´ØªÙØª ÙÙ‚Ø§Ø¹Ø§Øª Ø§ÙƒØ« ÙˆÙ„ÙƒÙ† Ù„ÙŠØ³ Ø§Ù„ÙƒÙ„ + Ø­Ø¬Ù…Ù‡Ø§ ÙƒØ¨ÙŠØ±











#############
#
###########
from ultralytics import YOLO
import os
import json
import cv2
import numpy as np

# ==========================
# ğŸ”¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
# ==========================
model_path = "model/model.pt"
image_folder = "images"
output_path = "C:/Users/abdoh/Downloads/01/cleaned/all_bubbles.json"

model = YOLO(model_path)

# ==========================
# ğŸ”¹ Ø¯Ø§Ù„Ø© ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ù‚Ø¨Ù„ Ø§Ù„ÙƒØ´Ù
# ==========================
def enhance_image_for_detection(image):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ HSV Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø©
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)

    # Ø±ÙØ¹ Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†
    v = cv2.equalizeHist(v)

    # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªØ´Ø¨Ø¹ Ù„ØªÙ‚Ù„ÙŠÙ„ ØªØ£Ø«ÙŠØ± Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø²Ø§Ù‡ÙŠØ©
    s = cv2.addWeighted(s, 0.7, np.zeros_like(s), 0, 0)

    hsv = cv2.merge([h, s, v])
    enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

    # ØªØ­ÙˆÙŠÙ„ Ù„ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ Ø®ÙÙŠÙ Ù…Ø¹ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¨Ø§ÙŠÙ†
    gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (3, 3), 0)
    gray = cv2.addWeighted(gray, 1.5, cv2.medianBlur(gray, 5), -0.5, 0)

    # Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© Ù…Ø¹ Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ø¥Ø¨Ø±Ø§Ø² Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„ØºØ§Ù…Ù‚Ø©
    final = cv2.addWeighted(enhanced, 0.7, cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), 0.3, 0)
    return final

# ==========================
# ğŸ”¹ Ø¯Ø§Ù„Ø© ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
# ==========================
def slice_image(image, slice_height=2500, overlap=100):
    h, w = image.shape[:2]
    slices = []
    start_y = 0
    while start_y < h:
        end_y = min(start_y + slice_height, h)
        slices.append((image[start_y:end_y, :].copy(), start_y))
        if end_y >= h:
            break
        start_y = end_y - overlap
    return slices

# ==========================
# ğŸ”¹ Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ¯Ø§Ø®Ù„ Ù„Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# ğŸ”¹ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ==========================
all_bubbles = {}

image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {img_path}")
        continue

    # âœ… ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ù„ÙˆÙ†Ø© Ø£Ùˆ Ø§Ù„Ø¯Ø§ÙƒÙ†Ø©
    enhanced_img = enhance_image_for_detection(image)

    h, w, _ = image.shape
    bubbles = []
    boxes = []

    # âœ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
    if h > 4000:
        slices = slice_image(enhanced_img)
        for slice_img, offset_y in slices:
            temp_path = f"temp_{offset_y}.jpg"
            cv2.imwrite(temp_path, slice_img)
            results = model(temp_path, imgsz=1280, conf=0.25)  # Ø²ÙˆØ¯ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ© Ù‚Ù„ÙŠÙ„Ø§Ù‹
            for r in results:
                if r.boxes:
                    for box, score in zip(r.boxes.xyxy, r.boxes.conf):
                        if score < 0.25:
                            continue
                        x1, y1, x2, y2 = box.tolist()
                        x1, y1, x2, y2 = x1, y1 + offset_y, x2, y2 + offset_y
                        if (x2 - x1) * (y2 - y1) < 2000:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØµÙ†Ø§Ø¯ÙŠÙ‚ Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
                            continue
                        duplicate = False
                        for b in boxes:
                            if box_iou(b, (x1, y1, x2, y2)) > 0.45:
                                duplicate = True
                                break
                        if not duplicate:
                            boxes.append((x1, y1, x2, y2))
                            bubbles.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])
            os.remove(temp_path)
    else:
        results = model(enhanced_img, imgsz=1280, conf=0.25)
        for r in results:
            if r.boxes:
                for box, score in zip(r.boxes.xyxy, r.boxes.conf):
                    if score < 0.25:
                        continue
                    x1, y1, x2, y2 = box.tolist()
                    if (x2 - x1) * (y2 - y1) < 2000:
                        continue
                    duplicate = False
                    for b in boxes:
                        if box_iou(b, (x1, y1, x2, y2)) > 0.45:
                            duplicate = True
                            break
                    if not duplicate:
                        boxes.append((x1, y1, x2, y2))
                        bubbles.append([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])

    # âœ… Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³
    key = f"{idx:02d}_mask"
    all_bubbles[key] = [{"id": i + 1, "points": [[int(x), int(y)] for x, y in b]} for i, b in enumerate(bubbles)]
    print(f"âœ… Processed {img_file}, found {len(bubbles)} unique bubbles.")

# ==========================
# ğŸ”¹ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ JSON
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2)

print(f"\nğŸ‰ All unique bubbles saved to:\n{output_path}")



# Ø§Ù‚Ø±Ø¨ Ø­Ø§Ø¬Ù‡ ØŸ

##############
###############
#################
###########################################
from ultralytics import YOLO
import easyocr
import os
import json
import cv2
import numpy as np
from shapely.geometry import Polygon

# ==========================
# ğŸ”¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
# ==========================
model_path = "model/model.pt"  # ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ±Ù‡ Ø¥Ù„Ù‰ model/comic-speech-bubble-detector.pt Ù„Ùˆ Ø¹Ø§ÙŠØ² Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰
image_folder = "images"
output_path = "C:/Users/abdoh/Downloads/01/cleaned/all_bubbles.json"

model = YOLO(model_path)
ocr = easyocr.Reader(['en', 'ar'], gpu=False)

# ==========================
# ğŸ”¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ù‚Ø¨Ù„ Ø§Ù„ÙƒØ´Ù
# ==========================
def enhance_image(img):
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    s = cv2.addWeighted(s, 0.7, np.zeros_like(s), 0, 0)
    hsv = cv2.merge([h, s, v])
    enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    lab = cv2.cvtColor(enhanced, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    lab = cv2.merge([l, a, b])
    enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    return enhanced

# ==========================
# ğŸ”¹ Ø¯Ø§Ù„Ø© Ø­Ø³Ø§Ø¨ IOU
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = (x2 - x1) * (y2 - y1)
    area2 = (X2 - X1) * (Y2 - Y1)
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

# ==========================
# ğŸ”¹ Ø­Ø°Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
# ==========================
def remove_duplicates(boxes, iou_thresh=0.45):
    unique = []
    for b in boxes:
        if all(box_iou(b, u) < iou_thresh for u in unique):
            unique.append(b)
    return unique

# ==========================
# ğŸ”¹ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø© Ø¥Ù„Ù‰ Ø´ÙƒÙ„ Ø¨ÙŠØ¶Ø§ÙˆÙŠ (Ø£Ùˆ Ø£ÙŠ Ø´ÙƒÙ„ Ø­Ø±)
# ==========================
def make_ellipse_path(x1, y1, x2, y2):
    cx = (x1 + x2) / 2
    cy = (y1 + y2) / 2
    rx = (x2 - x1) / 2
    ry = (y2 - y1) / 2
    points = []
    for angle in np.linspace(0, 2*np.pi, 36):
        x = cx + rx * np.cos(angle)
        y = cy + ry * np.sin(angle)
        points.append([int(x), int(y)])
    return points

# ==========================
# ğŸ”¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ==========================
all_bubbles = {}
image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {img_path}")
        continue

    enhanced = enhance_image(image)
    results = model(enhanced, imgsz=1280, conf=0.25)
    boxes = []

    for r in results:
        for box, conf in zip(r.boxes.xyxy, r.boxes.conf):
            if conf < 0.25:
                continue
            x1, y1, x2, y2 = map(int, box.tolist())
            area = (x2 - x1) * (y2 - y1)
            if area < 1500:
                continue

            crop = enhanced[y1:y2, x1:x2]
            gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)

            # ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙƒØ´Ù Ø§Ù„Ù†ØµÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø©
            blur = cv2.medianBlur(gray, 3)
            _, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

            text_result = ocr.readtext(binary)
            if len(text_result) == 0:
                continue

            # ğŸ”¹ Ø­Ø³Ø§Ø¨ Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù†ØµÙˆØµ Ø¯Ø§Ø®Ù„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø©
            text_area = 0
            for (bbox, text, conf_t) in text_result:
                if conf_t < 0.3 or not text.strip():
                    continue
                poly = Polygon(bbox)
                text_area += poly.area

            if text_area < area * 0.015:  # Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† ÙÙŠÙ‡ Ù†Øµ ÙØ¹Ù„ÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø©
                continue

            boxes.append((x1, y1, x2, y2))

    # Ø­Ø°Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
    boxes = remove_duplicates(boxes)
    bubbles = []

    for (x1, y1, x2, y2) in boxes:
        ellipse_points = make_ellipse_path(x1, y1, x2, y2)
        bubbles.append(ellipse_points)

    key = f"{idx:02d}_mask"
    all_bubbles[key] = [
        {"id": i + 1, "points": [[int(x), int(y)] for x, y in b]} for i, b in enumerate(bubbles)
    ]

    print(f"âœ… {img_file}: {len(bubbles)} ÙÙ‚Ø§Ø¹Ø© Ù…ÙƒØªØ´ÙØ© ØªØ­ØªÙˆÙŠ Ù†ØµÙˆØµ.")

# ==========================
# ğŸ”¹ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
# ==========================
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2, ensure_ascii=False)

print(f"\nğŸ‰ ØªÙ… Ø­ÙØ¸ ÙƒÙ„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ:\n{output_path}")


# ØŸØŸ Ø§ÙƒØ«Ø± Ø¯Ù‚Ù‡ ÙˆÙ„ÙƒÙ† Ø§Ù„ÙÙÙ‚Ø§Ø¹Ø§Øª Ù‚Ù„ÙŠÙ„Ù‡


from ultralytics import YOLO
import easyocr
import os
import json
import cv2
import numpy as np
from shapely.geometry import Polygon
from PIL import Image

# ==========================
# Paths / config
# ==========================
model_path = "model/model.pt"
image_folder = "images"
output_path = "C:/Users/abdoh/Downloads/01/cleaned/all_bubbles.json"
preview_folder = "previews"  # Ø³ÙŠÙÙ†Ø´Ø£ Ø¥Ù† Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§

# thresholds (Ø§Ù„Ø§Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Ù„Ù†Ø³Ø®ØªÙƒ Ø§Ù„ÙØ¹Ø§Ù„Ø©)
IMG_SZ = 1280
CONF_TH = 0.25
AREA_MIN = 1500          # ØªØ¬Ø§Ù‡Ù„ ØµÙ†Ø§Ø¯ÙŠÙ‚ Ø£ØµØºØ± Ù…Ù† ÙƒØ¯Ù‡
IOU_TH = 0.45
TEXT_AREA_RATIO = 0.015  # Ù†Ø³Ø¨Ø© Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù†Øµ Ø¯Ø§Ø®Ù„ Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚ Ù„Ù‚Ø¨ÙˆÙ„ Ø§Ù„ÙÙ‚Ø§Ø¹Ø©

# init models
model = YOLO(model_path)
ocr = easyocr.Reader(['en', 'ar'], gpu=False)

os.makedirs(preview_folder, exist_ok=True)

# ==========================
# image enhancement (Ø®ÙÙŠÙ ÙˆÙØ¹Ø§Ù„)
# ==========================
def enhance_image(img):
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.equalizeHist(v)
    s = cv2.addWeighted(s, 0.7, np.zeros_like(s), 0, 0)
    hsv = cv2.merge([h, s, v])
    enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    lab = cv2.cvtColor(enhanced, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    lab = cv2.merge([l, a, b])
    final = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    return final

# ==========================
# IoU Ùˆ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
# ==========================
def box_iou(box1, box2):
    x1, y1, x2, y2 = box1
    X1, Y1, X2, Y2 = box2
    inter_x1 = max(x1, X1)
    inter_y1 = max(y1, Y1)
    inter_x2 = min(x2, X2)
    inter_y2 = min(y2, Y2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    area1 = max(0, (x2 - x1)) * max(0, (y2 - y1))
    area2 = max(0, (X2 - X1)) * max(0, (Y2 - Y1))
    union = area1 + area2 - inter_area
    return inter_area / union if union > 0 else 0

def remove_duplicates(boxes, iou_thresh=IOU_TH):
    unique = []
    for b in boxes:
        if all(box_iou(b, u) < iou_thresh for u in unique):
            unique.append(b)
    return unique

# ==========================
# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­ÙˆØ§Ù Ø§Ù„ÙÙ‚Ø§Ø¹Ø© (Contour) â€” Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø´ÙƒÙ„ Ø­Ù‚ÙŠÙ‚ÙŠ
# ==========================
def extract_contour_path(img, box):
    x1, y1, x2, y2 = box
    h, w = img.shape[:2]
    # clamp
    x1, y1 = max(0, x1), max(0, y1)
    x2, y2 = min(w - 1, x2), min(h - 1, y2)
    if x2 <= x1 or y2 <= y1:
        return []
    crop = img[y1:y2, x1:x2]
    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blur, 50, 150)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return []
    # Ø§Ø®ØªØ§Ø± Ø£ÙƒØ¨Ø± ÙƒÙˆÙ†ØªÙˆØ± Ù…Ø¹ ÙÙ„ØªØ±Ø© Ø§Ù„Ù…Ø³Ø§Ø­Ø©
    largest = max(contours, key=cv2.contourArea)
    if cv2.contourArea(largest) < 0.02 * ((x2 - x1) * (y2 - y1)):
        return []
    eps = 0.01 * cv2.arcLength(largest, True)
    approx = cv2.approxPolyDP(largest, eps, True)
    points = [[int(x1 + p[0][0]), int(y1 + p[0][1])] for p in approx]
    return points

# ==========================
# ØµÙŠØ§ØºØ© Ù…Ø³Ø§Ø± Ø¨ÙŠØ¶Ø§ÙˆÙŠ Ø§Ø­ØªÙŠØ§Ø·ÙŠ
# ==========================
def make_ellipse_path(x1, y1, x2, y2, n=36):
    cx = (x1 + x2) / 2.0
    cy = (y1 + y2) / 2.0
    rx = (x2 - x1) / 2.0
    ry = (y2 - y1) / 2.0
    pts = []
    for angle in np.linspace(0, 2 * np.pi, n, endpoint=False):
        x = cx + rx * np.cos(angle)
        y = cy + ry * np.sin(angle)
        pts.append([int(round(x)), int(round(y))])
    return pts

# ==========================
# ØªØ¬Ø±Ø¨Ø© Ø¹Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø¨Ù„ Ø§Ù„Ù€OCR Ù„Ø§Ù„ØªÙ‚Ø§Ø· Ù†ØµÙˆØµ Ø¨ÙŠØ¶Ø§Ø¡/Ø³ÙˆØ¯Ø§Ø¡
# ==========================
def detect_text_inside_crop(crop, box_area):
    # crop: BGR numpy array
    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    variants = []

    # 1 - median + Otsu
    v1 = cv2.medianBlur(gray, 3)
    _, v1b = cv2.threshold(v1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    variants.append(v1b)

    # 2 - inverted binary (Ù„Ù†Øµ Ø£Ø¨ÙŠØ¶ Ø¹Ù„Ù‰ Ø¯Ø§ÙƒÙ†)
    variants.append(cv2.bitwise_not(v1b))

    # 3 - CLAHE Ø¹Ù„Ù‰ Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠ + Otsu
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    v3 = clahe.apply(gray)
    _, v3b = cv2.threshold(v3, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    variants.append(v3b)
    variants.append(cv2.bitwise_not(v3b))

    # 4 - adaptive gaussian
    try:
        v4 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY, 31, 9)
        variants.append(v4)
        variants.append(cv2.bitwise_not(v4))
    except Exception:
        pass

    # 5 - morphological close to reduce noise (on v1b)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    v_close = cv2.morphologyEx(v1b, cv2.MORPH_CLOSE, kernel, iterations=1)
    variants.append(v_close)

    # Ù†Ø¬Ø±Ù‘Ø¨ ÙƒÙ„ Ù†Ø³Ø®Ø© ÙˆÙ†Ø¹Ø·ÙŠ Ø§Ù„Ø£ÙØ¶Ù„
    best_text_area = 0
    for var in variants:
        try:
            # easyocr ÙŠØ¯Ø¹Ù… numpy arrays Ùˆ PIL.ImageØ› Ù†Ø¬Ø±Ù‘Ø¨ Ù…Ø¨Ø§Ø´Ø±Ø© numpy Ø£ÙˆÙ„Ø§Ù‹
            res = None
            try:
                res = ocr.readtext(var)
            except Exception:
                # fallback Ø¥Ù„Ù‰ PIL
                pil_img = Image.fromarray(var)
                res = ocr.readtext(pil_img)
        except Exception as e:
            # Ø·Ø¨Ø¹ Ø®Ø·Ø£ Ø§Ù„Ù€OCR Ù„Ù„debug Ù„ÙƒÙ† Ø§Ø³ØªÙ…Ø±
            # print("OCR exception:", e)
            res = []

        # Ø­Ø³Ø§Ø¨ Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        text_area = 0.0
        for item in res:
            try:
                bbox, text, conf = item
            except Exception:
                # Ø¨Ø¹Ø¶ Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª ØªØ¹ÙŠØ¯ (bbox, text, conf) Ø£Ùˆ Ø¹Ù†Ø§ØµØ± Ù…Ø®ØªÙ„ÙØ©Ø› Ù†Ø¹Ø§Ù„Ø¬ Ø¨Ø£Ù…Ø§Ù†
                if len(item) >= 3:
                    bbox = item[0]
                    text = item[1]
                    conf = float(item[2]) if len(item) > 2 else 0.0
                else:
                    continue

            if conf < 0.25 or not str(text).strip():
                continue
            try:
                poly = Polygon(bbox)
                text_area += abs(poly.area)
            except Exception:
                continue

        if text_area > best_text_area:
            best_text_area = text_area

        # Ù„Ùˆ Ù„Ù‚ÙŠ Ù†Øµ ÙƒØ§ÙÙŠ Ù†ÙˆÙ‚Ù
        if best_text_area >= box_area * TEXT_AREA_RATIO:
            return True, best_text_area

    return False, best_text_area

# ==========================
# Main loop
# ==========================
all_bubbles = {}
image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith((".jpg", ".png", ".jpeg"))])

for idx, img_file in enumerate(image_files, start=1):
    img_path = os.path.join(image_folder, img_file)
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {img_path}")
        continue

    # ØªØ¹Ø²ÙŠØ² Ø§Ù„ØµÙˆØ±Ø©
    enhanced = enhance_image(image)

    # run detector with the previously working settings
    results = model(enhanced, imgsz=IMG_SZ, conf=CONF_TH)
    candidate_boxes = []

    # gather boxes
    for r in results:
        for box, conf in zip(r.boxes.xyxy, r.boxes.conf):
            if conf < CONF_TH:
                continue
            x1, y1, x2, y2 = map(int, box.tolist())
            # clamp to image
            h, w = enhanced.shape[:2]
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(w - 1, x2), min(h - 1, y2)
            if x2 <= x1 or y2 <= y1:
                continue
            area = (x2 - x1) * (y2 - y1)
            if area < AREA_MIN:
                continue

            candidate_boxes.append((x1, y1, x2, y2))

    # remove duplicates
    candidate_boxes = remove_duplicates(candidate_boxes)

    # verify with OCR (multiple variants)
    accepted = []
    preview_img = image.copy()
    for box in candidate_boxes:
        x1, y1, x2, y2 = box
        crop = enhanced[y1:y2, x1:x2]
        ok, ta = detect_text_inside_crop(crop, (x2 - x1) * (y2 - y1))
        if ok:
            accepted.append(box)
            # draw preview rectangle
            cv2.rectangle(preview_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
        else:
            # Ø¶Ø¹ Ø®ÙÙŠÙ debug rectangle Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù„ÙŠ Ù„Ù… ØªÙ‚Ø¨Ù„ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            cv2.rectangle(preview_img, (x1, y1), (x2, y2), (0, 120, 255), 1)

    # final dedupe
    accepted = remove_duplicates(accepted)

    # build contours or ellipse fallback
    bubbles = []
    for box in accepted:
        pts = extract_contour_path(enhanced, box)
        if not pts or len(pts) < 3:
            x1, y1, x2, y2 = box
            pts = make_ellipse_path(x1, y1, x2, y2)
        bubbles.append(pts)

    # save preview image
    preview_path = os.path.join(preview_folder, f"preview_{img_file}")
    cv2.imwrite(preview_path, preview_img)

    # write to JSON structure
    key = f"{idx:02d}_mask"
    all_bubbles[key] = [
        {"id": i + 1, "points": [[int(x), int(y)] for x, y in b]} for i, b in enumerate(bubbles)
    ]

    print(f"âœ… {img_file}: detected {len(bubbles)} bubbles (preview saved -> {preview_path})")

# save JSON
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(all_bubbles, f, indent=2, ensure_ascii=False)

print(f"\nğŸ‰ Saved results to:\n{output_path}")
 # Ø¯Ù‚ÙŠÙ‚ ÙˆÙƒÙ„Ù† ÙÙ‚Ø§Ø¹ØªÙ‡ Ù‚Ù„ÙŠÙ„Ù‡ 